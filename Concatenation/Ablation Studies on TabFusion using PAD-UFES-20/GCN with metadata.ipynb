{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1cf7d-e12a-469e-b3c6-c37dee98db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # If you are using CUDA\n",
    "torch.backends.cudnn.deterministic = True  # For deterministic results\n",
    "torch.backends.cudnn.benchmark = False  # For consistency across different environments\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "IMAGE_DIR = 'D:\\\\PAD-UFES\\\\images'  \n",
    "METADATA_PATH = 'D:\\\\PAD-UFES\\\\metadata.csv'\n",
    "\n",
    "metadata = pd.read_csv(METADATA_PATH)\n",
    "\n",
    "def preprocess_metadata(metadata):\n",
    "    metadata = metadata.fillna('UNK')\n",
    "\n",
    "    boolean_cols = [\n",
    "        'smoke',\n",
    "        'drink',\n",
    "        'pesticide',\n",
    "        'skin_cancer_history',\n",
    "        'cancer_history',\n",
    "        'has_piped_water',\n",
    "        'has_sewage_system',\n",
    "        'itch',\n",
    "        'grew',\n",
    "        'hurt',\n",
    "        'changed',\n",
    "        'bleed',\n",
    "        'elevation',\n",
    "        'biopsed',\n",
    "    ]\n",
    "    # Ensure columns are strings and lowercase\n",
    "    for col in boolean_cols:\n",
    "        metadata[col] = metadata[col].astype(str).str.lower()\n",
    "    \n",
    "    # Map boolean columns to 1/0/-1\n",
    "    boolean_mapping = {'true': 1, 'false': 0, 'unk': -1}\n",
    "    for col in boolean_cols:\n",
    "        metadata[col] = metadata[col].map(boolean_mapping)\n",
    "    \n",
    "    # Handle categorical variables\n",
    "    categorical_cols = [\n",
    "        'background_father',\n",
    "        'background_mother',\n",
    "        'gender',\n",
    "        'region',\n",
    "        'diagnostic',\n",
    "    ]\n",
    "    # Convert categorical columns to string\n",
    "    for col in categorical_cols:\n",
    "        metadata[col] = metadata[col].astype(str)\n",
    "    \n",
    "    # One-hot encode categorical variables\n",
    "    metadata_encoded = pd.get_dummies(metadata[categorical_cols])\n",
    "    \n",
    "    # Normalize numerical variables\n",
    "    numerical_cols = ['age', 'fitspatrick', 'diameter_1', 'diameter_2']\n",
    "    # Ensure numerical columns are numeric\n",
    "    for col in numerical_cols:\n",
    "        metadata[col] = pd.to_numeric(metadata[col], errors='coerce')\n",
    "    # Fill NaNs in numerical columns with the mean\n",
    "    metadata[numerical_cols] = metadata[numerical_cols].fillna(metadata[numerical_cols].mean())\n",
    "    # Scale numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    metadata_numeric = metadata[numerical_cols]\n",
    "    metadata_numeric_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(metadata_numeric), columns=numerical_cols\n",
    "    )\n",
    "    \n",
    "    # Combine all metadata features\n",
    "    metadata_processed = pd.concat(\n",
    "        [metadata_numeric_scaled.reset_index(drop=True),\n",
    "         metadata_encoded.reset_index(drop=True),\n",
    "         metadata[boolean_cols].reset_index(drop=True)], axis=1\n",
    "    )\n",
    "    \n",
    "    return metadata_processed\n",
    "\n",
    "# Preprocess metadata\n",
    "metadata_processed = preprocess_metadata(metadata)\n",
    "\n",
    "def get_image_paths(metadata, image_dir):\n",
    "    image_paths = []\n",
    "    for idx, row in metadata.iterrows():\n",
    "        filename = row['img_id']\n",
    "        # Ensure filename is a string\n",
    "        filename = str(filename)\n",
    "        # Check if filename has an extension\n",
    "        if not filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Try common extensions\n",
    "            possible_extensions = ['.jpg', '.jpeg', '.png']\n",
    "            found = False\n",
    "            for ext in possible_extensions:\n",
    "                filepath = os.path.join(image_dir, filename + ext)\n",
    "                if os.path.isfile(filepath):\n",
    "                    image_paths.append(filepath)\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                print(f\"Image file not found for ID: {filename}\")\n",
    "                image_paths.append(None)\n",
    "        else:\n",
    "            filepath = os.path.join(image_dir, filename)\n",
    "            if os.path.isfile(filepath):\n",
    "                image_paths.append(filepath)\n",
    "            else:\n",
    "                print(f\"Image file not found: {filepath}\")\n",
    "                image_paths.append(None)\n",
    "    metadata['ImagePath'] = image_paths\n",
    "    return metadata\n",
    "\n",
    "metadata = get_image_paths(metadata, IMAGE_DIR)\n",
    "\n",
    "# Remove entries with missing images\n",
    "metadata = metadata[metadata['ImagePath'].notnull()]\n",
    "metadata_processed = metadata_processed.loc[metadata.index].reset_index(drop=True)\n",
    "metadata = metadata.reset_index(drop=True)\n",
    "\n",
    "# Drop diagnostic-related columns from features\n",
    "diagnostic_cols = ['diagnostic_ACK', 'diagnostic_BCC', 'diagnostic_MEL', 'diagnostic_NEV', 'diagnostic_SCC', 'diagnostic_SEK']\n",
    "metadata_processed = metadata_processed.drop(columns=diagnostic_cols)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(metadata['diagnostic'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Split data into features and labels\n",
    "X_meta = metadata_processed.reset_index(drop=True)\n",
    "X_img_paths = metadata['ImagePath'].reset_index(drop=True)\n",
    "y = pd.Series(y_encoded)\n",
    "\n",
    "X_train_meta, X_temp_meta, X_train_img_paths, X_temp_img_paths, y_train, y_temp = train_test_split(\n",
    "    X_meta,\n",
    "    X_img_paths,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_val_meta, X_test_meta, X_val_img_paths, X_test_img_paths, y_val, y_test = train_test_split(\n",
    "    X_temp_meta,\n",
    "    X_temp_img_paths,\n",
    "    y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "# Load augmented metadata + image paths\n",
    "aug_meta_df   = pd.read_csv(\"D:/PAD-UFES/augmented_metadata.csv\")\n",
    "aug_labels_df = pd.read_csv(\"D:/PAD-UFES/augmented_labels.csv\")\n",
    "\n",
    "# Combine augmented samples with training set\n",
    "X_train_meta_final = pd.concat([X_train_meta, aug_meta_df], ignore_index=True)\n",
    "X_train_img_paths_final = pd.concat([X_train_img_paths.reset_index(drop=True),\n",
    "                                     aug_labels_df['ImagePath']], ignore_index=True)\n",
    "y_train_final = pd.concat([y_train.reset_index(drop=True),\n",
    "                           aug_labels_df['Label']], ignore_index=True)\n",
    "\n",
    "class PADUFESDataset(Dataset):\n",
    "    def __init__(self, img_paths, meta_data, labels, transform=None):\n",
    "        self.img_paths = img_paths.reset_index(drop=True)\n",
    "        self.meta_data = meta_data.reset_index(drop=True)\n",
    "        self.labels = pd.Series(labels).reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        meta = torch.tensor(self.meta_data.iloc[idx].values.astype(np.float32))\n",
    "        label = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        return image, meta, label\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "    transforms.RandomRotation(70),          \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PADUFESDataset(X_train_img_paths_final, X_train_meta_final, y_train_final, transform=train_transform)\n",
    "val_dataset = PADUFESDataset(X_val_img_paths, X_val_meta, y_val, transform=val_test_transform)\n",
    "test_dataset = PADUFESDataset(X_test_img_paths, X_test_meta, y_test, transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"\\n✅ Loaded Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5bf25-69d0-4003-ba73-e17a09b30154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_cluster import knn_graph\n",
    "import timm\n",
    "\n",
    "\n",
    "class MetadataOnlyGCN(nn.Module):\n",
    "    def __init__(self, input_dim_meta, num_classes, k=8):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "\n",
    "        # ======== GCN (same as EarlyFusion) ========\n",
    "        self.gcn1 = GCNConv(input_dim_meta, 64)\n",
    "        self.gcn2 = GCNConv(64, 32)\n",
    "        self.res_proj = nn.Linear(64, 32)\n",
    "\n",
    "        # ======== Metadata → Pseudo-Image ========\n",
    "        self.meta_to_image = nn.Sequential(\n",
    "            nn.Linear(32, 56 * 56),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(56 * 56),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # ======== MobileViT Backbone ========\n",
    "        self.mobilevit = timm.create_model(\n",
    "            \"mobilevit_s.cvnets_in1k\",\n",
    "            pretrained=True,\n",
    "            num_classes=0\n",
    "        )\n",
    "\n",
    "        # Modify stem to accept ONLY 1 metadata channel\n",
    "        old_conv = self.mobilevit.stem.conv\n",
    "        new_conv = nn.Conv2d(\n",
    "            1,                                  # ONLY metadata pseudo-image\n",
    "            old_conv.out_channels,\n",
    "            kernel_size=old_conv.kernel_size,\n",
    "            stride=old_conv.stride,\n",
    "            padding=old_conv.padding,\n",
    "            bias=old_conv.bias is not None\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Initialize weights by averaging RGB channels\n",
    "            new_conv.weight[:] = old_conv.weight.mean(dim=1, keepdim=True)\n",
    "            if old_conv.bias is not None:\n",
    "                new_conv.bias[:] = old_conv.bias\n",
    "\n",
    "        self.mobilevit.stem.conv = new_conv\n",
    "\n",
    "        # Keep same MobileViT truncation as EarlyFusion model\n",
    "        self.mobilevit.stages = nn.Sequential(\n",
    "            *list(self.mobilevit.stages.children())[:4]\n",
    "        )\n",
    "\n",
    "        # Remove MobileViT classification head\n",
    "        self.mobilevit.final_conv = nn.Identity()\n",
    "        self.mobilevit.head = nn.Identity()\n",
    "\n",
    "        # ======== Post Conv (same as EarlyFusion) ========\n",
    "        self.post_conv = nn.Sequential(\n",
    "            nn.Conv2d(128, 160, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # ======== Classifier ========\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, meta, batch_idx):\n",
    "        B = meta.size(0)\n",
    "\n",
    "        # ----- Build KNN graph -----\n",
    "        edge_index = knn_graph(meta, k=self.k, batch=batch_idx)\n",
    "\n",
    "        # ----- GCN -----\n",
    "        x1 = F.relu(self.gcn1(meta, edge_index))\n",
    "        x2 = F.relu(self.gcn2(x1, edge_index) + self.res_proj(x1))\n",
    "        x_meta = x2  # [B, 32]\n",
    "\n",
    "        # ----- Metadata → pseudo-image -----\n",
    "        meta_img = self.meta_to_image(x_meta).view(B, 1, 56, 56)\n",
    "        meta_img = F.interpolate(\n",
    "            meta_img, size=(224, 224), mode='bilinear', align_corners=False\n",
    "        )\n",
    "\n",
    "        # ----- MobileViT processing -----\n",
    "        x = self.mobilevit.stem(meta_img)\n",
    "        x = self.mobilevit.stages(x)\n",
    "        x = self.post_conv(x)\n",
    "\n",
    "        # ----- Classification -----\n",
    "        x = self.pool(x).view(B, -1)  # [B, 160]\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "input_dim_meta = 59\n",
    "num_classes = 6\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MetadataOnlyGCN(input_dim_meta, num_classes).to(device)\n",
    "\n",
    "dummy_meta = torch.randn(batch_size, input_dim_meta).to(device)\n",
    "dummy_batch_idx = torch.arange(batch_size).to(device)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=[dummy_meta, dummy_batch_idx],\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    depth=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17147dbc-c29c-491e-a452-955d9e5f1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Utility Functions\n",
    "# =========================================================\n",
    "def set_seed(seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def evaluate_student(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, metas, labels in test_loader:\n",
    "            images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "            batch_indices = torch.arange(metas.size(0), device=device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(images, metas, batch_indices)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"Test Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall:    {recall:.4f}\")\n",
    "\n",
    "    return accuracy, f1, precision, recall\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Averaged Training Curve Plotting (with shaded mean ± std)\n",
    "# =========================================================\n",
    "def plot_average_training_curves(all_histories, save_path=\"averaged_training_curves.png\"):\n",
    "    # all_histories: dict of lists (one per seed), e.g.\n",
    "    # all_histories[\"train_loss\"] = [run1_list, run2_list, ...]\n",
    "\n",
    "    train_loss_runs = [np.array(run) for run in all_histories[\"train_loss\"]]\n",
    "    val_loss_runs   = [np.array(run) for run in all_histories[\"val_loss\"]]\n",
    "    train_acc_runs  = [np.array(run) for run in all_histories[\"train_acc\"]]\n",
    "    val_acc_runs    = [np.array(run) for run in all_histories[\"val_acc\"]]\n",
    "\n",
    "    # Align to same number of epochs (min across seeds, due to early stopping)\n",
    "    min_len = min(len(x) for x in train_loss_runs)\n",
    "\n",
    "    train_loss = np.stack([x[:min_len] for x in train_loss_runs])\n",
    "    val_loss   = np.stack([x[:min_len] for x in val_loss_runs])\n",
    "    train_acc  = np.stack([x[:min_len] for x in train_acc_runs])\n",
    "    val_acc    = np.stack([x[:min_len] for x in val_acc_runs])\n",
    "\n",
    "    epochs = np.arange(1, min_len + 1)\n",
    "\n",
    "    plt.rcParams['font.weight'] = 'bold'\n",
    "    plt.rcParams['axes.labelweight'] = 'bold'\n",
    "    plt.rcParams['axes.titleweight'] = 'bold'\n",
    "    plt.rcParams['xtick.labelsize'] = 12\n",
    "    plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # -------- Loss subplot --------\n",
    "    plt.subplot(1, 2, 1)\n",
    "    tl_mean, tl_std = train_loss.mean(axis=0), train_loss.std(axis=0)\n",
    "    vl_mean, vl_std = val_loss.mean(axis=0),   val_loss.std(axis=0)\n",
    "\n",
    "    plt.plot(epochs, tl_mean, label=\"Train Loss\")\n",
    "    plt.fill_between(epochs, tl_mean - tl_std, tl_mean + tl_std, alpha=0.25)\n",
    "\n",
    "    plt.plot(epochs, vl_mean, label=\"Validation Loss\")\n",
    "    plt.fill_between(epochs, vl_mean - vl_std, vl_mean + vl_std, alpha=0.25)\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss (Mean ± Std)\")\n",
    "    plt.legend()\n",
    "\n",
    "    # -------- Accuracy subplot --------\n",
    "    plt.subplot(1, 2, 2)\n",
    "    ta_mean, ta_std = train_acc.mean(axis=0), train_acc.std(axis=0)\n",
    "    va_mean, va_std = val_acc.mean(axis=0),   val_acc.std(axis=0)\n",
    "\n",
    "    plt.plot(epochs, ta_mean, label=\"Train Accuracy\")\n",
    "    plt.fill_between(epochs, ta_mean - ta_std, ta_mean + ta_std, alpha=0.25)\n",
    "\n",
    "    plt.plot(epochs, va_mean, label=\"Validation Accuracy\")\n",
    "    plt.fill_between(epochs, va_mean - va_std, va_mean + va_std, alpha=0.25)\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy (Mean ± Std)\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=650, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Training (No KD, standard supervised)\n",
    "# =========================================================\n",
    "def train_student_model(student_model, train_loader, val_loader,\n",
    "                        device, epochs=100, patience=10):\n",
    "\n",
    "    student_model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "    # Scheduler on validation accuracy → mode='max'\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=5, verbose=True)\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_val_model_state = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student_model.train()\n",
    "        train_loss_sum, correct, total = 0.0, 0, 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        for images, metas, labels in pbar:\n",
    "            images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "            batch_indices = torch.arange(metas.size(0), device=device, dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = student_model(images, metas, batch_indices)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_sum += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_loss = train_loss_sum / len(train_loader)\n",
    "        train_accuracy = correct / total\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_accuracy)\n",
    "\n",
    "        # ---- Validation ----\n",
    "        student_model.eval()\n",
    "        val_loss_sum, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, metas, labels in val_loader:\n",
    "                images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "                batch_indices = torch.arange(metas.size(0), device=device, dtype=torch.long)\n",
    "\n",
    "                outputs = student_model(images, metas, batch_indices)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss_sum += loss.item()\n",
    "\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_loss = val_loss_sum / len(val_loader)\n",
    "        val_accuracy = correct / total\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: \"\n",
    "              f\"Train Loss={train_loss:.4f}, Train Acc={train_accuracy:.4f} | \"\n",
    "              f\"Val Loss={val_loss:.4f}, Val Acc={val_accuracy:.4f}\")\n",
    "\n",
    "        # ---- Early Stopping on Val Accuracy ----\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_val_model_state = student_model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        # LR scheduling also on val accuracy\n",
    "        scheduler.step(val_accuracy)\n",
    "\n",
    "    return best_val_model_state, history, best_val_accuracy\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Main Experiment Loop (MULTI-SEED RUNS)\n",
    "# =========================================================\n",
    "seeds = [42, 123]\n",
    "best_overall_model = None\n",
    "best_overall_accuracy = 0.0\n",
    "\n",
    "results = {\"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": []}\n",
    "all_histories = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\n--- Training with Seed {seed} ---\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Make sure EarlyFusionWithMLPMeta is defined elsewhere:\n",
    "    # class EarlyFusionWithMLPMeta(nn.Module):\n",
    "    #     def forward(self, img, meta, batch_idx=None): ...\n",
    "    student_model = EarlyFusionWithMLPMeta(input_dim_meta=59, num_classes=6).to(device)\n",
    "\n",
    "    best_model_state, history, val_acc = train_student_model(\n",
    "        student_model=student_model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        epochs=100,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    # Store history for averaged curves\n",
    "    all_histories[\"train_loss\"].append(history[\"train_loss\"])\n",
    "    all_histories[\"val_loss\"].append(history[\"val_loss\"])\n",
    "    all_histories[\"train_acc\"].append(history[\"train_acc\"])\n",
    "    all_histories[\"val_acc\"].append(history[\"val_acc\"])\n",
    "\n",
    "    # ---- Final Test ----\n",
    "    student_model.load_state_dict(best_model_state)\n",
    "    acc, f1, prec, recall = evaluate_student(student_model, test_loader, device)\n",
    "\n",
    "    results[\"accuracy\"].append(acc)\n",
    "    results[\"f1\"].append(f1)\n",
    "    results[\"precision\"].append(prec)\n",
    "    results[\"recall\"].append(recall)\n",
    "\n",
    "    if val_acc > best_overall_accuracy:\n",
    "        best_overall_accuracy = val_acc\n",
    "        best_overall_model = student_model\n",
    "\n",
    "# ---- Save Best Model ----\n",
    "torch.save(best_overall_model.state_dict(), \"MLPwithImageAndMetadataNoKD.pth\")\n",
    "print(f\"\\nBest Val Accuracy Model Saved (Acc={best_overall_accuracy:.4f})\")\n",
    "\n",
    "# ---- Summary ----\n",
    "print(\"\\n--- Final Evaluation Across Seeds ---\")\n",
    "for metric in results:\n",
    "    print(f\"{metric.capitalize()}: {np.mean(results[metric]):.4f} ± {np.std(results[metric]):.4f}\")\n",
    "\n",
    "# ---- PLOT AVERAGED TRAINING CURVES ----\n",
    "plot_average_training_curves(all_histories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e4b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_overall_model.state_dict(), \"MetadataOnly_Model.pth\")\n",
    "print(f\"\\nBest Val Accuracy Model Saved (Acc={best_overall_accuracy:.4f})\")\n",
    "\n",
    "# Print final metrics\n",
    "for metric in results:\n",
    "    print(f\"{metric.capitalize()}: {np.mean(results[metric]):.4f} ± {np.std(results[metric]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27cfc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_training_curves(all_histories, save_path=\"averaged_training_curves.png\"):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Bold fonts\n",
    "    plt.rcParams['font.weight'] = 'bold'\n",
    "    plt.rcParams['axes.labelweight'] = 'bold'\n",
    "    plt.rcParams['axes.titleweight'] = 'bold'\n",
    "    plt.rcParams['xtick.labelsize'] = 12\n",
    "    plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "    # ---- Find max epoch length across all runs ----\n",
    "    max_epochs = max(len(h) for h in all_histories[\"train_loss\"])\n",
    "\n",
    "    # ---- Padding helper ----\n",
    "    def pad_list(l):\n",
    "        return l + [np.nan] * (max_epochs - len(l))\n",
    "\n",
    "    # ---- Convert histories to padded arrays ----\n",
    "    train_loss = np.array([pad_list(h) for h in all_histories[\"train_loss\"]])\n",
    "    val_loss   = np.array([pad_list(h) for h in all_histories[\"val_loss\"]])\n",
    "    train_acc  = np.array([pad_list(h) for h in all_histories[\"train_acc\"]])\n",
    "    val_acc    = np.array([pad_list(h) for h in all_histories[\"val_acc\"]])\n",
    "\n",
    "    epochs = np.arange(1, max_epochs + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # ===== Loss subplot =====\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, np.nanmean(train_loss, axis=0), label=\"Train Loss\")\n",
    "    plt.fill_between(epochs,\n",
    "                     np.nanmean(train_loss, axis=0) - np.nanstd(train_loss, axis=0),\n",
    "                     np.nanmean(train_loss, axis=0) + np.nanstd(train_loss, axis=0),\n",
    "                     alpha=0.25)\n",
    "    plt.plot(epochs, np.nanmean(val_loss, axis=0), label=\"Validation Loss\")\n",
    "    plt.fill_between(epochs,\n",
    "                     np.nanmean(val_loss, axis=0) - np.nanstd(val_loss, axis=0),\n",
    "                     np.nanmean(val_loss, axis=0) + np.nanstd(val_loss, axis=0),\n",
    "                     alpha=0.25)\n",
    "\n",
    "    plt.xlabel(\"Epochs\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"Loss\", fontweight=\"bold\")\n",
    "    plt.title(\"Training and Validation Loss (Averaged Across Runs)\", fontweight=\"bold\")\n",
    "    plt.legend()\n",
    "\n",
    "    # ===== Accuracy subplot =====\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, np.nanmean(train_acc, axis=0), label=\"Train Accuracy\")\n",
    "    plt.fill_between(epochs,\n",
    "                     np.nanmean(train_acc, axis=0) - np.nanstd(train_acc, axis=0),\n",
    "                     np.nanmean(train_acc, axis=0) + np.nanstd(train_acc, axis=0),\n",
    "                     alpha=0.25)\n",
    "    plt.plot(epochs, np.nanmean(val_acc, axis=0), label=\"Validation Accuracy\")\n",
    "    plt.fill_between(epochs,\n",
    "                     np.nanmean(val_acc, axis=0) - np.nanstd(val_acc, axis=0),\n",
    "                     np.nanmean(val_acc, axis=0) + np.nanstd(val_acc, axis=0),\n",
    "                     alpha=0.25)\n",
    "\n",
    "    plt.xlabel(\"Epochs\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"Accuracy\", fontweight=\"bold\")\n",
    "    plt.title(\"Training and Validation Accuracy (Averaged Across Runs)\", fontweight=\"bold\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_average_training_curves(all_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e445513-187f-4d9a-a981-8a88908ab80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the best model for evaluation\n",
    "best_model = MetadataOnlyGCN(input_dim_meta=59, num_classes=6).to(device)\n",
    "best_model.load_state_dict(torch.load(\"MetadataOnly_Model.pth\"))\n",
    "best_model.eval()\n",
    "\n",
    "# Collect true labels and predictions\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#             for images, metas, labels in val_loader:  # ✔ Fix applied\n",
    "#                 metas, labels = metas.to(device), labels.to(device)\n",
    "#                 batch_indices = torch.arange(metas.size(0)).to(device)\n",
    "\n",
    "#                 outputs = model(meta=metas, batch_idx=batch_indices)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 val_loss += loss.item()\n",
    "\n",
    "#                 _, predicted = outputs.max(1)\n",
    "#                 correct += predicted.eq(labels).sum().item()\n",
    "#                 total += labels.size(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for images, metas, labels in test_loader:\n",
    "        metas, labels = metas.to(device), labels.to(device)\n",
    "        batch_indices = torch.arange(metas.size(0)).to(device).long()\n",
    "        outputs = best_model(meta=metas, batch_idx=batch_indices)  # Only pass metadata\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# Get class names from label encoder\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Compute classification report\n",
    "class_report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
    "\n",
    "# Compute normalized confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds, normalize=\"true\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(class_report)\n",
    "\n",
    "# Display confusion matrix (Blues colormap)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\".2f\", xticklabels=class_names, yticklabels=class_names, cbar=True)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot ROC-AUC curve for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    fpr, tpr, _ = roc_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")  # Diagonal line for reference\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC-AUC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot Precision-Recall Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    precision, recall, _ = precision_recall_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{class_name}\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "params_m = count_parameters(model) / 1e6\n",
    "print(f\"Total Trainable Parameters: {params_m:.3f} M\")\n",
    "\n",
    "\n",
    "# Wrapper for metadata-only model to work with ptflops\n",
    "class MetadataWrapper(nn.Module):\n",
    "    def __init__(self, model, meta_dim=59):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.meta_dim = meta_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is dummy input, create metadata tensor\n",
    "        batch = x.shape[0]\n",
    "        dummy_meta = torch.randn(batch, self.meta_dim).to(x.device)\n",
    "        dummy_batch_idx = torch.arange(batch).to(x.device)\n",
    "        return self.model(meta=dummy_meta, batch_idx=dummy_batch_idx)\n",
    "\n",
    "wrapper = MetadataWrapper(model, meta_dim=59).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    flops, params = get_model_complexity_info(\n",
    "        wrapper,\n",
    "        (3, 224, 224),          # dummy image input (will be replaced inside wrapper)\n",
    "        as_strings=False,\n",
    "        print_per_layer_stat=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "flops_g = flops / 1e9\n",
    "print(f\"FLOPs: {flops_g:.3f} GFLOPs\")\n",
    "\n",
    "\n",
    "def measure_gpu_latency(model, device, meta_dim=59, runs=200, warmup=30):\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA not available, skipping GPU latency.\")\n",
    "        return None, None, None\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Fixed dummy input - metadata only\n",
    "    dummy_meta = torch.randn(1, meta_dim, device=device)\n",
    "    dummy_batch_idx = torch.arange(1, device=device)\n",
    "\n",
    "    # Warm-up\n",
    "    for _ in range(warmup):\n",
    "        _ = model(meta=dummy_meta, batch_idx=dummy_batch_idx)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    times = []\n",
    "\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    for _ in range(runs):\n",
    "        start_event.record()\n",
    "        _ = model(meta=dummy_meta, batch_idx=dummy_batch_idx)\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        elapsed_ms = start_event.elapsed_time(end_event)  # ms\n",
    "        times.append(elapsed_ms)\n",
    "\n",
    "    times = np.array(times)\n",
    "    mean = times.mean()\n",
    "    std = times.std()\n",
    "    fps = 1000.0 / mean\n",
    "    return mean, std, fps\n",
    "\n",
    "gpu_mean, gpu_std, gpu_fps = measure_gpu_latency(model, device, meta_dim=59)\n",
    "\n",
    "if gpu_mean is not None:\n",
    "    print(f\"GPU Latency: {gpu_mean:.3f} ± {gpu_std:.3f} ms\")\n",
    "    print(f\"GPU FPS: {gpu_fps:.2f}\")\n",
    "else:\n",
    "    print(\"GPU metrics not computed (no CUDA).\")\n",
    "\n",
    "\n",
    "def measure_cpu_latency(model, meta_dim=59, runs=100, warmup=20):\n",
    "    model_cpu = model.cpu()\n",
    "    model_cpu.eval()\n",
    "\n",
    "    dummy_meta = torch.randn(1, meta_dim)\n",
    "    dummy_batch_idx = torch.arange(1)\n",
    "\n",
    "    # Warm-up\n",
    "    for _ in range(warmup):\n",
    "        _ = model_cpu(meta=dummy_meta, batch_idx=dummy_batch_idx)\n",
    "\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        start = time.perf_counter()\n",
    "        _ = model_cpu(meta=dummy_meta, batch_idx=dummy_batch_idx)\n",
    "        end = time.perf_counter()\n",
    "        times.append((end - start) * 1000.0)  # ms\n",
    "\n",
    "    times = np.array(times)\n",
    "    mean = times.mean()\n",
    "    std = times.std()\n",
    "    fps = 1000.0 / mean\n",
    "    return mean, std, fps\n",
    "\n",
    "cpu_mean, cpu_std, cpu_fps = measure_cpu_latency(model, meta_dim=59)\n",
    "print(f\"CPU Latency: {cpu_mean:.3f} ± {cpu_std:.3f} ms\")\n",
    "print(f\"CPU FPS: {cpu_fps:.2f}\")\n",
    "\n",
    "\n",
    "efficiency_stats = {\n",
    "    \"params_M\": params_m,\n",
    "    \"flops_G\": flops_g,\n",
    "    \"gpu_latency_ms_mean\": gpu_mean,\n",
    "    \"gpu_latency_ms_std\": gpu_std,\n",
    "    \"gpu_fps\": gpu_fps,\n",
    "    \"cpu_latency_ms_mean\": cpu_mean,\n",
    "    \"cpu_latency_ms_std\": cpu_std,\n",
    "    \"cpu_fps\": cpu_fps,\n",
    "}\n",
    "\n",
    "print(\"\\nEfficiency stats dict (for your table):\")\n",
    "for k, v in efficiency_stats.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
