{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1cf7d-e12a-469e-b3c6-c37dee98db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # If you are using CUDA\n",
    "torch.backends.cudnn.deterministic = True  # For deterministic results\n",
    "torch.backends.cudnn.benchmark = False  # For consistency across different environments\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "IMAGE_DIR = 'D:\\\\PAD-UFES\\\\images'  \n",
    "METADATA_PATH = 'D:\\\\PAD-UFES\\\\metadata.csv'\n",
    "\n",
    "metadata = pd.read_csv(METADATA_PATH)\n",
    "\n",
    "def preprocess_metadata(metadata):\n",
    "    metadata = metadata.fillna('UNK')\n",
    "\n",
    "    boolean_cols = [\n",
    "        'smoke',\n",
    "        'drink',\n",
    "        'pesticide',\n",
    "        'skin_cancer_history',\n",
    "        'cancer_history',\n",
    "        'has_piped_water',\n",
    "        'has_sewage_system',\n",
    "        'itch',\n",
    "        'grew',\n",
    "        'hurt',\n",
    "        'changed',\n",
    "        'bleed',\n",
    "        'elevation',\n",
    "        'biopsed',\n",
    "    ]\n",
    "    # Ensure columns are strings and lowercase\n",
    "    for col in boolean_cols:\n",
    "        metadata[col] = metadata[col].astype(str).str.lower()\n",
    "    \n",
    "    # Map boolean columns to 1/0/-1\n",
    "    boolean_mapping = {'true': 1, 'false': 0, 'unk': -1}\n",
    "    for col in boolean_cols:\n",
    "        metadata[col] = metadata[col].map(boolean_mapping)\n",
    "    \n",
    "    # Handle categorical variables\n",
    "    categorical_cols = [\n",
    "        'background_father',\n",
    "        'background_mother',\n",
    "        'gender',\n",
    "        'region',\n",
    "        'diagnostic',\n",
    "    ]\n",
    "    # Convert categorical columns to string\n",
    "    for col in categorical_cols:\n",
    "        metadata[col] = metadata[col].astype(str)\n",
    "    \n",
    "    # One-hot encode categorical variables\n",
    "    metadata_encoded = pd.get_dummies(metadata[categorical_cols])\n",
    "    \n",
    "    # Normalize numerical variables\n",
    "    numerical_cols = ['age', 'fitspatrick', 'diameter_1', 'diameter_2']\n",
    "    # Ensure numerical columns are numeric\n",
    "    for col in numerical_cols:\n",
    "        metadata[col] = pd.to_numeric(metadata[col], errors='coerce')\n",
    "    # Fill NaNs in numerical columns with the mean\n",
    "    metadata[numerical_cols] = metadata[numerical_cols].fillna(metadata[numerical_cols].mean())\n",
    "    # Scale numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    metadata_numeric = metadata[numerical_cols]\n",
    "    metadata_numeric_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(metadata_numeric), columns=numerical_cols\n",
    "    )\n",
    "    \n",
    "    # Combine all metadata features\n",
    "    metadata_processed = pd.concat(\n",
    "        [metadata_numeric_scaled.reset_index(drop=True),\n",
    "         metadata_encoded.reset_index(drop=True),\n",
    "         metadata[boolean_cols].reset_index(drop=True)], axis=1\n",
    "    )\n",
    "    \n",
    "    return metadata_processed\n",
    "\n",
    "# Preprocess metadata\n",
    "metadata_processed = preprocess_metadata(metadata)\n",
    "\n",
    "def get_image_paths(metadata, image_dir):\n",
    "    image_paths = []\n",
    "    for idx, row in metadata.iterrows():\n",
    "        filename = row['img_id']\n",
    "        # Ensure filename is a string\n",
    "        filename = str(filename)\n",
    "        # Check if filename has an extension\n",
    "        if not filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Try common extensions\n",
    "            possible_extensions = ['.jpg', '.jpeg', '.png']\n",
    "            found = False\n",
    "            for ext in possible_extensions:\n",
    "                filepath = os.path.join(image_dir, filename + ext)\n",
    "                if os.path.isfile(filepath):\n",
    "                    image_paths.append(filepath)\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                print(f\"Image file not found for ID: {filename}\")\n",
    "                image_paths.append(None)\n",
    "        else:\n",
    "            filepath = os.path.join(image_dir, filename)\n",
    "            if os.path.isfile(filepath):\n",
    "                image_paths.append(filepath)\n",
    "            else:\n",
    "                print(f\"Image file not found: {filepath}\")\n",
    "                image_paths.append(None)\n",
    "    metadata['ImagePath'] = image_paths\n",
    "    return metadata\n",
    "\n",
    "metadata = get_image_paths(metadata, IMAGE_DIR)\n",
    "\n",
    "# Remove entries with missing images\n",
    "metadata = metadata[metadata['ImagePath'].notnull()]\n",
    "metadata_processed = metadata_processed.loc[metadata.index].reset_index(drop=True)\n",
    "metadata = metadata.reset_index(drop=True)\n",
    "\n",
    "# Drop diagnostic-related columns from features\n",
    "diagnostic_cols = ['diagnostic_ACK', 'diagnostic_BCC', 'diagnostic_MEL', 'diagnostic_NEV', 'diagnostic_SCC', 'diagnostic_SEK']\n",
    "metadata_processed = metadata_processed.drop(columns=diagnostic_cols)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(metadata['diagnostic'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Split data into features and labels\n",
    "X_meta = metadata_processed.reset_index(drop=True)\n",
    "X_img_paths = metadata['ImagePath'].reset_index(drop=True)\n",
    "y = pd.Series(y_encoded)\n",
    "\n",
    "X_train_meta, X_temp_meta, X_train_img_paths, X_temp_img_paths, y_train, y_temp = train_test_split(\n",
    "    X_meta,\n",
    "    X_img_paths,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_val_meta, X_test_meta, X_val_img_paths, X_test_img_paths, y_val, y_test = train_test_split(\n",
    "    X_temp_meta,\n",
    "    X_temp_img_paths,\n",
    "    y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "# Load augmented metadata + image paths\n",
    "aug_meta_df   = pd.read_csv(\"D:/PAD-UFES/augmented_metadata.csv\")\n",
    "aug_labels_df = pd.read_csv(\"D:/PAD-UFES/augmented_labels.csv\")\n",
    "\n",
    "# Combine augmented samples with training set\n",
    "X_train_meta_final = pd.concat([X_train_meta, aug_meta_df], ignore_index=True)\n",
    "X_train_img_paths_final = pd.concat([X_train_img_paths.reset_index(drop=True),\n",
    "                                     aug_labels_df['ImagePath']], ignore_index=True)\n",
    "y_train_final = pd.concat([y_train.reset_index(drop=True),\n",
    "                           aug_labels_df['Label']], ignore_index=True)\n",
    "\n",
    "class PADUFESDataset(Dataset):\n",
    "    def __init__(self, img_paths, meta_data, labels, transform=None):\n",
    "        self.img_paths = img_paths.reset_index(drop=True)\n",
    "        self.meta_data = meta_data.reset_index(drop=True)\n",
    "        self.labels = pd.Series(labels).reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        meta = torch.tensor(self.meta_data.iloc[idx].values.astype(np.float32))\n",
    "        label = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        return image, meta, label\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "    transforms.RandomRotation(70),          \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PADUFESDataset(X_train_img_paths_final, X_train_meta_final, y_train_final, transform=train_transform)\n",
    "val_dataset = PADUFESDataset(X_val_img_paths, X_val_meta, y_val, transform=val_test_transform)\n",
    "test_dataset = PADUFESDataset(X_test_img_paths, X_test_meta, y_test, transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"\\n✅ Loaded Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5bf25-69d0-4003-ba73-e17a09b30154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_cluster import knn_graph\n",
    "import timm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_cluster import knn_graph\n",
    "import timm\n",
    "\n",
    "\n",
    "class EarlyFusionWithDynamicGCN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # === MobileViT Backbone (Original - 3 channels only) ===\n",
    "        self.mobilevit = timm.create_model(\"mobilevit_s.cvnets_in1k\", pretrained=True, num_classes=0)\n",
    "        \n",
    "        # Keep original stem - no modification needed for 3-channel input\n",
    "        self.mobilevit.stages = nn.Sequential(*list(self.mobilevit.stages.children())[:4])\n",
    "        self.mobilevit.final_conv = nn.Identity()\n",
    "        self.mobilevit.head = nn.Identity()\n",
    "\n",
    "        # === Post Conv ===\n",
    "        self.post_conv = nn.Sequential(\n",
    "            nn.Conv2d(128, 160, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # === Classifier ===\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, meta=None, batch_idx=None):\n",
    "        # Only use image - ignore metadata and batch_idx\n",
    "        B = img.size(0)\n",
    "\n",
    "        # CNN processing\n",
    "        x_cnn = self.mobilevit.stem(img)  # [B, 3, 224, 224] -> features\n",
    "        x_cnn = self.mobilevit.stages(x_cnn)\n",
    "        x_cnn = self.post_conv(x_cnn)\n",
    "        x_cnn = self.pool(x_cnn).view(B, -1)  # [B, 160]\n",
    "\n",
    "        return self.classifier(x_cnn)\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "input_dim_meta = 59\n",
    "num_classes = 6\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EarlyFusionWithDynamicGCN(num_classes).to(device)\n",
    "\n",
    "dummy_img = torch.randn(batch_size, 3, 224, 224).to(device)\n",
    "dummy_meta = torch.randn(batch_size, input_dim_meta).to(device)\n",
    "dummy_batch_idx = torch.arange(batch_size).to(device)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=[dummy_img, dummy_meta, dummy_batch_idx],\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    depth=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17147dbc-c29c-491e-a452-955d9e5f1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Utility Functions\n",
    "# =========================================================\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, metas, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)  # Only pass image\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "\n",
    "    return accuracy, f1, precision, recall\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# NEW: Averaged Training Curve Plotting\n",
    "# =========================================================\n",
    "def plot_average_training_curves(all_histories, save_path=\"averaged_training_curves.png\"):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # ---- Set global bold font ----\n",
    "    plt.rcParams['font.weight'] = 'bold'\n",
    "    plt.rcParams['axes.labelweight'] = 'bold'\n",
    "    plt.rcParams['axes.titleweight'] = 'bold'\n",
    "    plt.rcParams['xtick.labelsize'] = 12\n",
    "    plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "    train_loss = np.array(all_histories[\"train_loss\"])\n",
    "    val_loss = np.array(all_histories[\"val_loss\"])\n",
    "    train_acc = np.array(all_histories[\"train_acc\"])\n",
    "    val_acc = np.array(all_histories[\"val_acc\"])\n",
    "\n",
    "    epochs = np.arange(1, train_loss.shape[1] + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # -------- Loss subplot --------\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    plt.plot(epochs, train_loss.mean(axis=0), label=\"Train Loss\")\n",
    "    plt.fill_between(\n",
    "        epochs,\n",
    "        train_loss.mean(axis=0) - train_loss.std(axis=0),\n",
    "        train_loss.mean(axis=0) + train_loss.std(axis=0),\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    plt.plot(epochs, val_loss.mean(axis=0), label=\"Validation Loss\")\n",
    "    plt.fill_between(\n",
    "        epochs,\n",
    "        val_loss.mean(axis=0) - val_loss.std(axis=0),\n",
    "        val_loss.mean(axis=0) + val_loss.std(axis=0),\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Epochs\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"Loss\", fontweight=\"bold\")\n",
    "    plt.title(\"Training and Validation Loss (Averaged Across Runs)\", fontweight=\"bold\")\n",
    "    plt.legend()\n",
    "\n",
    "    # -------- Accuracy subplot --------\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    plt.plot(epochs, train_acc.mean(axis=0), label=\"Train Accuracy\")\n",
    "    plt.fill_between(\n",
    "        epochs,\n",
    "        train_acc.mean(axis=0) - train_acc.std(axis=0),\n",
    "        train_acc.mean(axis=0) + train_acc.std(axis=0),\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    plt.plot(epochs, val_acc.mean(axis=0), label=\"Validation Accuracy\")\n",
    "    plt.fill_between(\n",
    "        epochs,\n",
    "        val_acc.mean(axis=0) - val_acc.std(axis=0),\n",
    "        val_acc.mean(axis=0) + val_acc.std(axis=0),\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Epochs\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"Accuracy\", fontweight=\"bold\")\n",
    "    plt.title(\"Training and Validation Accuracy (Averaged Across Runs)\", fontweight=\"bold\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ---- SAVE AT 650 DPI ----\n",
    "    plt.savefig(save_path, dpi=650, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, epochs=100, patience=10):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=5, verbose=True)\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        for images, metas, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # Only pass image\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        history[\"train_loss\"].append(train_loss / len(train_loader))\n",
    "        history[\"train_acc\"].append(train_accuracy)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, metas, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)  # Only pass image\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_accuracy = correct / total\n",
    "        history[\"val_loss\"].append(val_loss / len(val_loader))\n",
    "        history[\"val_acc\"].append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={train_loss/len(train_loader):.4f}, Train Acc={train_accuracy:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}: Val Loss={val_loss/len(val_loader):.4f}, Val Acc={val_accuracy:.4f}\")\n",
    "\n",
    "        # Early Stopping\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        scheduler.step(val_accuracy)\n",
    "\n",
    "    return best_model_state, history, best_val_accuracy\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Main Experiment Loop (MULTI-SEED RUNS)\n",
    "# =========================================================\n",
    "\n",
    "seeds = [42, 123]\n",
    "best_overall_model = None\n",
    "best_overall_accuracy = 0.0\n",
    "\n",
    "results = {\"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": []}\n",
    "\n",
    "# NEW: store histories for averaging\n",
    "all_histories = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\n--- Training with Seed {seed} ---\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    model = EarlyFusionWithDynamicGCN(num_classes=6).to(device)\n",
    "\n",
    "    best_model_state, history, val_acc = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        epochs=100,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    # Store history for averaged curves\n",
    "    all_histories[\"train_loss\"].append(history[\"train_loss\"])\n",
    "    all_histories[\"val_loss\"].append(history[\"val_loss\"])\n",
    "    all_histories[\"train_acc\"].append(history[\"train_acc\"])\n",
    "    all_histories[\"val_acc\"].append(history[\"val_acc\"])\n",
    "\n",
    "    # ---- Final Test ----\n",
    "    model.load_state_dict(best_model_state)\n",
    "    acc, f1, prec, recall = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    results[\"accuracy\"].append(acc)\n",
    "    results[\"f1\"].append(f1)\n",
    "    results[\"precision\"].append(prec)\n",
    "    results[\"recall\"].append(recall)\n",
    "\n",
    "    if val_acc > best_overall_accuracy:\n",
    "        best_overall_accuracy = val_acc\n",
    "        best_overall_model = model\n",
    "\n",
    "# ---- Save Best Model ----\n",
    "torch.save(best_overall_model.state_dict(), \"ImageOnly_Model.pth\")\n",
    "print(f\"\\nBest Val Accuracy Model Saved (Acc={best_overall_accuracy:.4f})\")\n",
    "\n",
    "# ---- Summary ----\n",
    "print(\"\\n--- Final Evaluation Across Seeds ---\")\n",
    "for metric in results:\n",
    "    print(f\"{metric.capitalize()}: {np.mean(results[metric]):.4f} ± {np.std(results[metric]):.4f}\")\n",
    "\n",
    "# ---- PLOT AVERAGED TRAINING CURVES ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0421e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_training_curves(all_histories, save_path=\"averaged_training_curves.png\"):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Bold fonts\n",
    "    plt.rcParams['font.weight'] = 'bold'\n",
    "    plt.rcParams['axes.labelweight'] = 'bold'\n",
    "    plt.rcParams['axes.titleweight'] = 'bold'\n",
    "    plt.rcParams['xtick.labelsize'] = 12\n",
    "    plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "    # ---- Find max epoch length across all runs ----\n",
    "    max_epochs = max(len(h) for h in all_histories[\"train_loss\"])\n",
    "\n",
    "    # ---- Padding helper ----\n",
    "    def pad_list(l):\n",
    "        return l + [np.nan] * (max_epochs - len(l))\n",
    "\n",
    "    # ---- Convert histories to padded arrays ----\n",
    "    train_loss = np.array([pad_list(h) for h in all_histories[\"train_loss\"]])\n",
    "    val_loss   = np.array([pad_list(h) for h in all_histories[\"val_loss\"]])\n",
    "    train_acc  = np.array([pad_list(h) for h in all_histories[\"train_acc\"]])\n",
    "    val_acc    = np.array([pad_list(h) for h in all_histories[\"val_acc\"]])\n",
    "\n",
    "    epochs = np.arange(1, max_epochs + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # ===== Loss subplot =====\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, np.nanmean(train_loss, axis=0), label=\"Train Loss\")\n",
    "    plt.fill_between(epochs,\n",
    "                     np.nanmean(train_loss, axis=0) - np.nanstd(train_loss, axis=0),\n",
    "                     np.nanmean(train_loss, axis=0) + np.nanstd(train_loss, axis=0),\n",
    "                     alpha=0.25)\n",
    "    plt.plot(epochs, np.nanmean(val_loss, axis=0), label=\"Validation Loss\")\n",
    "    plt.fill_between(epochs,\n",
    "                     np.nanmean(val_loss, axis=0) - np.nanstd(val_loss, axis=0),\n",
    "                     np.nanmean(val_loss, axis=0) + np.nanstd(val_loss, axis=0),\n",
    "                     alpha=0.25)\n",
    "\n",
    "    plt.xlabel(\"Epochs\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"Loss\", fontweight=\"bold\")\n",
    "    plt.title(\"Training and Validation Loss (Averaged Across Runs)\", fontweight=\"bold\")\n",
    "    plt.legend()\n",
    "\n",
    "    # ===== Accuracy subplot =====\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, np.nanmean(train_acc, axis=0), label=\"Train Accuracy\")\n",
    "    plt.fill_between(epochs,\n",
    "                     np.nanmean(train_acc, axis=0) - np.nanstd(train_acc, axis=0),\n",
    "                     np.nanmean(train_acc, axis=0) + np.nanstd(train_acc, axis=0),\n",
    "                     alpha=0.25)\n",
    "    plt.plot(epochs, np.nanmean(val_acc, axis=0), label=\"Validation Accuracy\")\n",
    "    plt.fill_between(epochs,\n",
    "                     np.nanmean(val_acc, axis=0) - np.nanstd(val_acc, axis=0),\n",
    "                     np.nanmean(val_acc, axis=0) + np.nanstd(val_acc, axis=0),\n",
    "                     alpha=0.25)\n",
    "\n",
    "    plt.xlabel(\"Epochs\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"Accuracy\", fontweight=\"bold\")\n",
    "    plt.title(\"Training and Validation Accuracy (Averaged Across Runs)\", fontweight=\"bold\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_average_training_curves(all_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d070d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "params_m = count_parameters(model) / 1e6\n",
    "print(f\"Total Trainable Parameters: {params_m:.3f} M\")\n",
    "\n",
    "\n",
    "# For image-only model, no wrapper needed - direct FLOPs measurement\n",
    "with torch.no_grad():\n",
    "    flops, params = get_model_complexity_info(\n",
    "        model,\n",
    "        (3, 224, 224),          # image only input\n",
    "        as_strings=False,\n",
    "        print_per_layer_stat=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "flops_g = flops / 1e9\n",
    "print(f\"FLOPs: {flops_g:.3f} GFLOPs\")\n",
    "\n",
    "\n",
    "def measure_gpu_latency(model, device, runs=200, warmup=30):\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA not available, skipping GPU latency.\")\n",
    "        return None, None, None\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Fixed dummy input - image only\n",
    "    dummy_img = torch.randn(1, 3, 224, 224, device=device)\n",
    "\n",
    "    # Warm-up\n",
    "    for _ in range(warmup):\n",
    "        _ = model(dummy_img)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    times = []\n",
    "\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    for _ in range(runs):\n",
    "        start_event.record()\n",
    "        _ = model(dummy_img)\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        elapsed_ms = start_event.elapsed_time(end_event)  # ms\n",
    "        times.append(elapsed_ms)\n",
    "\n",
    "    times = np.array(times)\n",
    "    mean = times.mean()\n",
    "    std = times.std()\n",
    "    fps = 1000.0 / mean\n",
    "    return mean, std, fps\n",
    "\n",
    "gpu_mean, gpu_std, gpu_fps = measure_gpu_latency(model, device)\n",
    "\n",
    "if gpu_mean is not None:\n",
    "    print(f\"GPU Latency: {gpu_mean:.3f} ± {gpu_std:.3f} ms\")\n",
    "    print(f\"GPU FPS: {gpu_fps:.2f}\")\n",
    "else:\n",
    "    print(\"GPU metrics not computed (no CUDA).\")\n",
    "\n",
    "\n",
    "def measure_cpu_latency(model, runs=100, warmup=20):\n",
    "    model_cpu = model.cpu()\n",
    "    model_cpu.eval()\n",
    "\n",
    "    dummy_img = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "    # Warm-up\n",
    "    for _ in range(warmup):\n",
    "        _ = model_cpu(dummy_img)\n",
    "\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        start = time.perf_counter()\n",
    "        _ = model_cpu(dummy_img)\n",
    "        end = time.perf_counter()\n",
    "        times.append((end - start) * 1000.0)  # ms\n",
    "\n",
    "    times = np.array(times)\n",
    "    mean = times.mean()\n",
    "    std = times.std()\n",
    "    fps = 1000.0 / mean\n",
    "    return mean, std, fps\n",
    "\n",
    "cpu_mean, cpu_std, cpu_fps = measure_cpu_latency(model)\n",
    "print(f\"CPU Latency: {cpu_mean:.3f} ± {cpu_std:.3f} ms\")\n",
    "print(f\"CPU FPS: {cpu_fps:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "efficiency_stats = {\n",
    "    \"params_M\": params_m,\n",
    "    \"flops_G\": flops_g,\n",
    "    \"gpu_latency_ms_mean\": gpu_mean,\n",
    "    \"gpu_latency_ms_std\": gpu_std,\n",
    "    \"gpu_fps\": gpu_fps,\n",
    "    \"cpu_latency_ms_mean\": cpu_mean,\n",
    "    \"cpu_latency_ms_std\": cpu_std,\n",
    "    \"cpu_fps\": cpu_fps,\n",
    "}\n",
    "\n",
    "print(\"\\nEfficiency stats dict (for your table):\")\n",
    "for k, v in efficiency_stats.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e445513-187f-4d9a-a981-8a88908ab80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the best model for evaluation\n",
    "best_model = EarlyFusionWithDynamicGCN(num_classes=6).to(device)\n",
    "best_model.load_state_dict(torch.load(\"ImageOnly_Model.pth\"))\n",
    "best_model.eval()\n",
    "\n",
    "# Collect true labels and predictions\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, metas, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)  # Only pass image\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# Get class names from label encoder\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Compute classification report\n",
    "class_report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
    "\n",
    "# Compute normalized confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds, normalize=\"true\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(class_report)\n",
    "\n",
    "# Display confusion matrix (Blues colormap)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\".2f\", xticklabels=class_names, yticklabels=class_names, cbar=True)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot ROC-AUC curve for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    fpr, tpr, _ = roc_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")  # Diagonal line for reference\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC-AUC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot Precision-Recall Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    precision, recall, _ = precision_recall_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{class_name}\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
