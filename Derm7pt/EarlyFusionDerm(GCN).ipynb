{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1cf7d-e12a-469e-b3c6-c37dee98db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# DERM7PT DATA LOADER FOR TRAINING NOTEBOOKS\n",
    "# =========================================================\n",
    "# Run this code in your training notebooks to load the preprocessed Derm7pt dataset\n",
    "# Make sure the preprocessing pipeline above has been executed first!\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# =========================================================\n",
    "# PATHS TO PREPROCESSED DATA\n",
    "# =========================================================\n",
    "PREPROCESSED_DIR = r\"augmented\"\n",
    "\n",
    "TRAIN_CSV = os.path.join(PREPROCESSED_DIR, \"train_metadata_final.csv\")\n",
    "VAL_CSV   = os.path.join(PREPROCESSED_DIR, \"val_metadata_final.csv\")\n",
    "TEST_CSV  = os.path.join(PREPROCESSED_DIR, \"test_metadata_final.csv\")\n",
    "\n",
    "INFO_PATH = os.path.join(PREPROCESSED_DIR, \"preprocessing_info.json\")\n",
    "\n",
    "# =========================================================\n",
    "# LOAD PREPROCESSED DATA\n",
    "# =========================================================\n",
    "print(\"Loading preprocessed Derm7pt data...\")\n",
    "\n",
    "# Load CSVs\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df   = pd.read_csv(VAL_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Load preprocessing info\n",
    "with open(INFO_PATH, \"r\") as f:\n",
    "    preprocessing_info = json.load(f)\n",
    "\n",
    "categorical_cols = preprocessing_info[\"categorical_cols\"]\n",
    "label_mapping = preprocessing_info[\"label_mapping\"]\n",
    "\n",
    "# Extract class names from label_mapping (sorted by label index)\n",
    "class_names = [k for k, v in sorted(label_mapping.items(), key=lambda x: x[1])]\n",
    "\n",
    "print(f\"\\n‚úÖ Training samples:   {len(train_df)}\")\n",
    "print(f\"‚úÖ Validation samples: {len(val_df)}\")\n",
    "print(f\"‚úÖ Test samples:       {len(test_df)}\")\n",
    "print(f\"\\nLabel mapping: {label_mapping}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# =========================================================\n",
    "# EXTRACT FEATURES AND LABELS\n",
    "# =========================================================\n",
    "def extract_features(df):\n",
    "    \"\"\"Extract image paths, metadata features, and labels from dataframe\"\"\"\n",
    "    img_paths = df[\"ImagePath\"].values\n",
    "    labels = df[\"label\"].values\n",
    "    \n",
    "    # Metadata features (all columns except ImagePath and label)\n",
    "    metadata_cols = [col for col in df.columns if col not in [\"ImagePath\", \"label\"]]\n",
    "    metadata = df[metadata_cols].values\n",
    "    \n",
    "    return img_paths, metadata, labels\n",
    "\n",
    "X_train_img, X_train_meta, y_train = extract_features(train_df)\n",
    "X_val_img, X_val_meta, y_val       = extract_features(val_df)\n",
    "X_test_img, X_test_meta, y_test    = extract_features(test_df)\n",
    "\n",
    "num_classes = len(label_mapping)\n",
    "print(f\"\\nNumber of classes: {num_classes}\")\n",
    "\n",
    "# =========================================================\n",
    "# PYTORCH DATASET CLASS\n",
    "# =========================================================\n",
    "class Derm7ptDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for Derm7pt with images + metadata\n",
    "    \"\"\"\n",
    "    def __init__(self, img_paths, metadata, labels, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.metadata = metadata\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.img_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            # Fallback to black image if loading fails\n",
    "            print(f\"Warning: Failed to load {img_path}, using placeholder\")\n",
    "            image = Image.new(\"RGB\", (224, 224), color=\"black\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get metadata and label\n",
    "        metadata = self.metadata[idx].astype(np.float32)\n",
    "        label = int(self.labels[idx])\n",
    "        \n",
    "        return image, metadata, label\n",
    "\n",
    "# =========================================================\n",
    "# DATA TRANSFORMS\n",
    "# =========================================================\n",
    "# Training transforms (with augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# =========================================================\n",
    "# CREATE DATASETS\n",
    "# =========================================================\n",
    "train_dataset = Derm7ptDataset(X_train_img, X_train_meta, y_train, transform=train_transform)\n",
    "val_dataset   = Derm7ptDataset(X_val_img, X_val_meta, y_val, transform=val_test_transform)\n",
    "test_dataset  = Derm7ptDataset(X_test_img, X_test_meta, y_test, transform=val_test_transform)\n",
    "\n",
    "print(f\"\\n‚úÖ Created PyTorch Datasets\")\n",
    "print(f\"   - Train: {len(train_dataset)} samples\")\n",
    "print(f\"   - Val:   {len(val_dataset)} samples\")\n",
    "print(f\"   - Test:  {len(test_dataset)} samples\")\n",
    "\n",
    "# =========================================================\n",
    "# CREATE DATALOADERS (EXAMPLE - ADJUST BATCH SIZE AS NEEDED)\n",
    "# =========================================================\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Set to 0 for Windows, increase for Linux/Mac\n",
    "    pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Created DataLoaders (batch_size={BATCH_SIZE})\")\n",
    "print(f\"   - Train batches: {len(train_loader)}\")\n",
    "print(f\"   - Val batches:   {len(val_loader)}\")\n",
    "print(f\"   - Test batches:  {len(test_loader)}\")\n",
    "\n",
    "# =========================================================\n",
    "# EXAMPLE: TEST LOADING A BATCH\n",
    "# =========================================================\n",
    "print(\"\\nüîç Testing batch loading...\")\n",
    "for images, metadata, labels in train_loader:\n",
    "    print(f\"   - Image batch shape:    {images.shape}\")\n",
    "    print(f\"   - Metadata batch shape: {metadata.shape}\")\n",
    "    print(f\"   - Labels batch shape:   {labels.shape}\")\n",
    "    break\n",
    "\n",
    "print(\"\\n‚úÖ Derm7pt data loading complete! Ready for training.\")\n",
    "print(\"\\nüí° Usage in your model:\")\n",
    "print(\"   for images, metadata, labels in train_loader:\")\n",
    "print(\"       # images: torch.Tensor of shape (batch_size, 3, 224, 224)\")\n",
    "print(\"       # metadata: torch.Tensor of shape (batch_size, num_metadata_features)\")\n",
    "print(\"       # labels: torch.Tensor of shape (batch_size,)\")\n",
    "print(\"       # Your training code here...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33069a53-51bc-4407-8b9e-09e0d68acbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = train_df['label'].nunique()\n",
    "print(\"Number of classes:\", num_classes)\n",
    "non_feature_cols = [\"label\", \"ImagePath\"]\n",
    "X_train_meta = train_df.drop(columns=non_feature_cols)\n",
    "input_dim_meta = X_train_meta.shape[1]\n",
    "print(f\"Metadata input dimension: {input_dim_meta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95beed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def test(model, loader, device, desc=\"Testing\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, metas, labels in tqdm(loader, total=len(loader), desc=desc, unit=\"batch\"):\n",
    "            imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
    "            outputs = model(imgs, metas)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "            running_total += labels.size(0)\n",
    "            tqdm.write(f\"Batch acc: {running_correct / running_total:.4f}\")\n",
    "\n",
    "    return all_labels, all_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ddf23-3575-4c08-bfaf-73158d8caa83",
   "metadata": {},
   "source": [
    "<h1>MobileViT</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be60655-13a0-4cf0-91ef-73a62c6062b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm  \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EarlyFusionModel(nn.Module):\n",
    "    def __init__(self, input_dim_meta, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embed metadata to smaller spatial dimensions first\n",
    "        self.meta_embed = nn.Sequential(\n",
    "            nn.Linear(input_dim_meta, 64 * 64),  # Updated for mobilevit's smaller receptive field\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64 * 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Load MobileViT model\n",
    "        self.mobilevit = timm.create_model(\"mobilevit_s.cvnets_in1k\", pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "        # Inspect the model to identify the first conv layer\n",
    "        # Modify the first conv layer to accept additional channel\n",
    "        first_conv = self.mobilevit.stem.conv  # `stem.conv` is the correct initial layer\n",
    "        self.mobilevit.stem.conv = nn.Conv2d(4, first_conv.out_channels, \n",
    "                                             kernel_size=first_conv.kernel_size, \n",
    "                                             stride=first_conv.stride, \n",
    "                                             padding=first_conv.padding, \n",
    "                                             bias=first_conv.bias)\n",
    "        \n",
    "        # Initialize new channel weights\n",
    "        with torch.no_grad():\n",
    "            self.mobilevit.stem.conv.weight.data[:, :3] = first_conv.weight.data\n",
    "            # Initialize the new channel with smaller weights to prevent dominating\n",
    "            self.mobilevit.stem.conv.weight.data[:, 3:] = first_conv.weight.data.mean(dim=1, keepdim=True) * 0.1\n",
    "\n",
    "    def forward(self, img, meta):\n",
    "        # Reshape metadata to image-like format\n",
    "        batch_size = img.shape[0]\n",
    "        meta_reshaped = self.meta_embed(meta).view(batch_size, 1, 64, 64)\n",
    "        \n",
    "        # Upsample to match image dimensions\n",
    "        meta_upsampled = F.interpolate(meta_reshaped, \n",
    "                                       size=(224, 224),  # MobileViT expects 256x256\n",
    "                                       mode='bilinear', \n",
    "                                       align_corners=False)\n",
    "        \n",
    "        # Early fusion\n",
    "        combined_input = torch.cat([img, meta_upsampled], dim=1)\n",
    "        \n",
    "        # Process through modified MobileViT\n",
    "        out = self.mobilevit(combined_input)\n",
    "        return out\n",
    "\n",
    "# Assuming X_train_meta and other variables are defined\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EarlyFusionModel(input_dim_meta, num_classes).to(device)\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model=model, \n",
    "        input_size=[(16, 3, 224, 224), (16, input_dim_meta)],  # Updated for MobileViT input size\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")\n",
    "\n",
    "mobilevit_model = EarlyFusionModel(input_dim_meta=input_dim_meta, num_classes=num_classes).to(device)\n",
    "mobilevit_model.load_state_dict(torch.load('D:\\\\Dermp7\\\\best_early_fusion_mobilevitsmoteDA.pth'))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mobilevit_model.to(device)\n",
    "\n",
    "true_labels, pred_labels = test(mobilevit_model, test_loader, device)\n",
    "\n",
    "report = classification_report(true_labels, pred_labels, digits=4,target_names=class_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "cm = confusion_matrix(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223cb9a-4391-44cf-911d-07084c698624",
   "metadata": {},
   "source": [
    "<h1>PvtV2</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43becc93-75ae-470e-ab2c-3eca7a877442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EarlyFusionModel(nn.Module):\n",
    "    def __init__(self, input_dim_meta, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embed metadata to smaller spatial dimensions first\n",
    "        self.meta_embed = nn.Sequential(\n",
    "            nn.Linear(input_dim_meta, 56 * 56),  # Smaller initial dimension\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(56 * 56),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Load PVT v2 model\n",
    "        self.pvt = timm.create_model(\"pvt_v2_b1\", pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "        # Modify the first convolution layer to accept additional channel (4 instead of 3)\n",
    "        first_conv = self.pvt.patch_embed.proj\n",
    "        self.pvt.patch_embed.proj = nn.Conv2d(4, first_conv.out_channels, \n",
    "                                              kernel_size=first_conv.kernel_size,\n",
    "                                              stride=first_conv.stride,\n",
    "                                              padding=first_conv.padding,\n",
    "                                              bias=first_conv.bias is not None)\n",
    "        \n",
    "        # Initialize new channel weights\n",
    "        with torch.no_grad():\n",
    "            self.pvt.patch_embed.proj.weight.data[:, :3] = first_conv.weight.data\n",
    "            self.pvt.patch_embed.proj.weight.data[:, 3:] = first_conv.weight.data.mean(dim=1, keepdim=True) * 0.1\n",
    "\n",
    "    def forward(self, img, meta):\n",
    "        # Reshape metadata to image-like format\n",
    "        batch_size = img.shape[0]\n",
    "        meta_reshaped = self.meta_embed(meta).view(batch_size, 1, 56, 56)\n",
    "        \n",
    "        # Upsample to match image dimensions\n",
    "        meta_upsampled = F.interpolate(meta_reshaped, \n",
    "                                       size=(224, 224), \n",
    "                                       mode='bilinear', \n",
    "                                       align_corners=False)\n",
    "        \n",
    "        # Early fusion\n",
    "        combined_input = torch.cat([img, meta_upsampled], dim=1)\n",
    "        \n",
    "        # Process through modified PVT\n",
    "        out = self.pvt(combined_input)\n",
    "        return out\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EarlyFusionModel(input_dim_meta, num_classes).to(device)\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model=model, \n",
    "        input_size=[(16, 3, 224, 224), (16, input_dim_meta)],  \n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")\n",
    "\n",
    "pv2_model = EarlyFusionModel(input_dim_meta=input_dim_meta, num_classes=num_classes).to(device)\n",
    "pv2_model.load_state_dict(torch.load('D:\\\\Dermp7\\\\best_early_fusion_pvtv2smoteDA.pth'))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pv2_model.to(device)\n",
    "\n",
    "true_labels, pred_labels = test(pv2_model, test_loader, device)\n",
    "\n",
    "report = classification_report(true_labels, pred_labels, digits=4,target_names=class_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "cm = confusion_matrix(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c7618-8f12-4d5c-9368-2bcd95b49a89",
   "metadata": {},
   "source": [
    "<h1>Teacher Model (Mean Averaging)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a95b15c-e8a5-4669-859e-81bd46f30aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self, models, ensemble_method=\"mean\"):\n",
    "        \"\"\"\n",
    "        Teacher Model using Ensemble Learning.\n",
    "\n",
    "        Args:\n",
    "            models (list): List of trained models to use for ensembling.\n",
    "            ensemble_method (str): \"mean\" for averaging logits, \"vote\" for majority voting.\n",
    "        \"\"\"\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.models = models\n",
    "        self.ensemble_method = ensemble_method\n",
    "\n",
    "        # Ensure all models are in eval mode and no gradients are computed\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, img, meta):\n",
    "        \"\"\"\n",
    "        Forward pass through the ensemble teacher model.\n",
    "\n",
    "        Args:\n",
    "            img (torch.Tensor): Batch of images.\n",
    "            meta (torch.Tensor): Batch of metadata.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The ensembled output (soft probabilities).\n",
    "        \"\"\"\n",
    "        model_outputs = []\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation for teacher\n",
    "            for model in self.models:\n",
    "                outputs = model(img, meta)\n",
    "                model_outputs.append(outputs)\n",
    "\n",
    "        # Convert list to tensor shape [num_models, batch_size, num_classes]\n",
    "        model_outputs = torch.stack(model_outputs, dim=0)\n",
    "\n",
    "        if self.ensemble_method == \"mean\":\n",
    "            # Soft-label generation: Averaging logits\n",
    "            avg_outputs = model_outputs.mean(dim=0)  \n",
    "        elif self.ensemble_method == \"vote\":\n",
    "            # Majority voting: Get the most common prediction\n",
    "            _, predictions = torch.max(model_outputs, dim=2) \n",
    "            avg_outputs = predictions.mode(dim=0).values  \n",
    "\n",
    "        return avg_outputs \n",
    "\n",
    "teacher_model = TeacherModel(models=[mobilevit_model, pv2_model], ensemble_method=\"mean\")\n",
    "\n",
    "# Move to the correct device (CPU/GPU)\n",
    "teacher_model = teacher_model.to(device)\n",
    "\n",
    "true_labels, pred_labels = test(teacher_model, test_loader, device)\n",
    "\n",
    "report = classification_report(true_labels, pred_labels, digits=4,target_names=class_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "cm = confusion_matrix(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252176ef-94fb-4d22-b869-1e39d2f4cbf2",
   "metadata": {},
   "source": [
    "<h1>Knowledge Distillation on Student Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5bf25-69d0-4003-ba73-e17a09b30154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_cluster import knn_graph\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# IMPROVED MODEL (A FIXED TO MATCH B'S BEHAVIOR)\n",
    "# =========================================================\n",
    "class EarlyFusionWithGCN(nn.Module):\n",
    "    def __init__(self, input_dim_meta, num_classes, k=8):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "\n",
    "        # --- GCN Layers ---\n",
    "        self.gcn1 = GCNConv(input_dim_meta, 64)\n",
    "        self.gcn2 = GCNConv(64, 32)\n",
    "        self.res_proj = nn.Linear(64, 32)\n",
    "\n",
    "        # --- metadata ‚Üí pseudo image ---\n",
    "        self.meta_to_image = nn.Sequential(\n",
    "            nn.Linear(32, 56 * 56),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(56 * 56),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # --- MobileViT backbone ---\n",
    "        self.mobilevit = timm.create_model(\n",
    "            \"mobilevit_s.cvnets_in1k\",\n",
    "            pretrained=True,\n",
    "            num_classes=0\n",
    "        )\n",
    "\n",
    "        # --- Modify first conv to accept 4 channels ---\n",
    "        stem_conv = self.mobilevit.stem.conv\n",
    "        new_conv = nn.Conv2d(\n",
    "            4, stem_conv.out_channels,\n",
    "            kernel_size=stem_conv.kernel_size,\n",
    "            stride=stem_conv.stride,\n",
    "            padding=stem_conv.padding,\n",
    "            bias=stem_conv.bias is not None\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # copy RGB weights\n",
    "            new_conv.weight[:, :3] = stem_conv.weight\n",
    "            # tiny weight for metadata channel\n",
    "            new_conv.weight[:, 3:] = stem_conv.weight.mean(dim=1, keepdim=True) * 0.1\n",
    "            # copy bias if exists\n",
    "            if stem_conv.bias is not None:\n",
    "                new_conv.bias = stem_conv.bias.clone()\n",
    "\n",
    "        self.mobilevit.stem.conv = new_conv\n",
    "\n",
    "        # keep only first 4 stages\n",
    "        self.mobilevit.stages = nn.Sequential(\n",
    "            *list(self.mobilevit.stages.children())[:4]\n",
    "        )\n",
    "        self.mobilevit.final_conv = nn.Identity()\n",
    "        self.mobilevit.head = nn.Identity()\n",
    "\n",
    "        # --- Post Conv ---\n",
    "        self.post_conv = nn.Sequential(\n",
    "            nn.Conv2d(128, 160, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # --- Classifier ---\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, meta, batch_idx):\n",
    "        B = meta.size(0)\n",
    "\n",
    "        # CORRECT: dynamic kNN graph WITHOUT self-loops\n",
    "        edge_index = knn_graph(meta, k=self.k, batch=batch_idx)\n",
    "\n",
    "        # GCN + residual\n",
    "        x1 = F.relu(self.gcn1(meta, edge_index))\n",
    "        x2 = F.relu(self.gcn2(x1, edge_index) + self.res_proj(x1))\n",
    "\n",
    "        # Metadata ‚Üí pseudo-image\n",
    "        meta_img = self.meta_to_image(x2).view(B, 1, 56, 56)\n",
    "        meta_img = F.interpolate(meta_img, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        # Early fusion (4 channels)\n",
    "        x = torch.cat([img, meta_img], dim=1)\n",
    "\n",
    "        # CNN forward\n",
    "        feats = self.mobilevit.stem(x)\n",
    "        feats = self.mobilevit.stages(feats)\n",
    "        feats = self.post_conv(feats)\n",
    "        feats = self.pool(feats).view(B, -1)\n",
    "\n",
    "        return self.classifier(feats)\n",
    "    \n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EarlyFusionWithGCN(input_dim_meta, num_classes).to(device)\n",
    "\n",
    "dummy_img = torch.randn(batch_size, 3, 224, 224).to(device)\n",
    "dummy_meta = torch.randn(batch_size, input_dim_meta).to(device)\n",
    "dummy_batch_idx = torch.arange(batch_size).to(device)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=[dummy_img, dummy_meta, dummy_batch_idx],\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    depth=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17147dbc-c29c-491e-a452-955d9e5f1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Teacher Model (Assumed Already Defined and Loaded)\n",
    "# =========================================================\n",
    "teacher_model = TeacherModel(models=[mobilevit_model, pv2_model], ensemble_method=\"mean\").to(device)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Utility Functions\n",
    "# =========================================================\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def evaluate_student(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, metas, labels in test_loader:\n",
    "            images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "            batch_indices = torch.arange(metas.size(0)).to(device).long()\n",
    "            outputs = model(images, metas, batch_indices)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "\n",
    "    return accuracy, f1, precision, recall\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# NEW: Averaged Training Curve Plotting (FIXED)\n",
    "# =========================================================\n",
    "def plot_average_training_curves(all_histories, save_path=\"averaged_training_curves.png\"):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # ---- Set global bold font ----\n",
    "    plt.rcParams['font.weight'] = 'bold'\n",
    "    plt.rcParams['axes.labelweight'] = 'bold'\n",
    "    plt.rcParams['axes.titleweight'] = 'bold'\n",
    "    plt.rcParams['xtick.labelsize'] = 12\n",
    "    plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "    # ---- FIXED: Pad histories to the same length ----\n",
    "    max_epochs = max(len(h) for h in all_histories[\"train_loss\"])\n",
    "    \n",
    "    def pad_history(history_list, max_len):\n",
    "        \"\"\"Pad each history to max_len using the last value\"\"\"\n",
    "        padded = []\n",
    "        for hist in history_list:\n",
    "            if len(hist) < max_len:\n",
    "                # Pad with the last value\n",
    "                padded.append(hist + [hist[-1]] * (max_len - len(hist)))\n",
    "            else:\n",
    "                padded.append(hist)\n",
    "        return np.array(padded)\n",
    "    \n",
    "    train_loss = pad_history(all_histories[\"train_loss\"], max_epochs)\n",
    "    val_loss = pad_history(all_histories[\"val_loss\"], max_epochs)\n",
    "    train_acc = pad_history(all_histories[\"train_acc\"], max_epochs)\n",
    "    val_acc = pad_history(all_histories[\"val_acc\"], max_epochs)\n",
    "\n",
    "    epochs = np.arange(1, max_epochs + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # -------- Loss subplot --------\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    plt.plot(epochs, train_loss.mean(axis=0), label=\"Train Loss\")\n",
    "    plt.fill_between(\n",
    "        epochs,\n",
    "        train_loss.mean(axis=0) - train_loss.std(axis=0),\n",
    "        train_loss.mean(axis=0) + train_loss.std(axis=0),\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    plt.plot(epochs, val_loss.mean(axis=0), label=\"Validation Loss\")\n",
    "    plt.fill_between(\n",
    "        epochs,\n",
    "        val_loss.mean(axis=0) - val_loss.std(axis=0),\n",
    "        val_loss.mean(axis=0) + val_loss.std(axis=0),\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Epochs\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"Loss\", fontweight=\"bold\")\n",
    "    plt.title(\"Training and Validation Loss (Averaged Across Runs)\", fontweight=\"bold\")\n",
    "    plt.legend()\n",
    "\n",
    "    # -------- Accuracy subplot --------\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    plt.plot(epochs, train_acc.mean(axis=0), label=\"Train Accuracy\")\n",
    "    plt.fill_between(\n",
    "        epochs,\n",
    "        train_acc.mean(axis=0) - train_acc.std(axis=0),\n",
    "        train_acc.mean(axis=0) + train_acc.std(axis=0),\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    plt.plot(epochs, val_acc.mean(axis=0), label=\"Validation Accuracy\")\n",
    "    plt.fill_between(\n",
    "        epochs,\n",
    "        val_acc.mean(axis=0) - val_acc.std(axis=0),\n",
    "        val_acc.mean(axis=0) + val_acc.std(axis=0),\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Epochs\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"Accuracy\", fontweight=\"bold\")\n",
    "    plt.title(\"Training and Validation Accuracy (Averaged Across Runs)\", fontweight=\"bold\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ---- SAVE AT 650 DPI ----\n",
    "    plt.savefig(save_path, dpi=650, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Training with Knowledge Distillation\n",
    "# =========================================================\n",
    "def train_student_model_kd(student_model, teacher_model, train_loader, val_loader, test_loader,\n",
    "                           device, alpha=0.5, temperature=3.0, epochs=100, patience=10):\n",
    "\n",
    "    student_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    kl_div_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=5, verbose=True)\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_val_model_state = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student_model.train()\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        for images, metas, labels in pbar:\n",
    "            images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "            batch_indices = torch.arange(metas.size(0)).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            student_outputs = student_model(images, metas, batch_indices)\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(images, metas)\n",
    "\n",
    "            # --- Hard loss ---\n",
    "            loss_hard = criterion(student_outputs, labels)\n",
    "\n",
    "            # --- Soft loss (KD) ---\n",
    "            loss_soft = kl_div_loss(\n",
    "                F.log_softmax(student_outputs / temperature, dim=1),\n",
    "                F.softmax(teacher_outputs / temperature, dim=1)\n",
    "            )\n",
    "\n",
    "            loss = (1 - alpha) * loss_hard + alpha * (temperature ** 2) * loss_soft\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = student_outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_accuracy)\n",
    "\n",
    "        # ---- Validation ----\n",
    "        student_model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, metas, labels in val_loader:\n",
    "                images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "                batch_indices = torch.arange(metas.size(0)).to(device)\n",
    "                outputs = student_model(images, metas, batch_indices)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_accuracy = correct / total\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_accuracy:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}: Val Loss={val_loss:.4f}, Val Acc={val_accuracy:.4f}\")\n",
    "\n",
    "        # ---- Early Stopping ----\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_val_model_state = student_model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    return best_val_model_state, history, best_val_accuracy\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Main Experiment Loop (MULTI-SEED RUNS)\n",
    "# =========================================================\n",
    "\n",
    "seeds = [42, 123, 569]\n",
    "best_overall_model = None\n",
    "best_overall_accuracy = 0.0\n",
    "\n",
    "results = {\"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": []}\n",
    "\n",
    "# NEW: store histories for averaging\n",
    "all_histories = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\n--- Training with Seed {seed} ---\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    student_model = EarlyFusionWithGCN(input_dim_meta, num_classes).to(device)\n",
    "\n",
    "    best_model_state, history, val_acc = train_student_model_kd(\n",
    "        student_model=student_model,\n",
    "        teacher_model=teacher_model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        alpha=0.2,\n",
    "        temperature=9.0,\n",
    "        epochs=100,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    # Store history for averaged curves\n",
    "    all_histories[\"train_loss\"].append(history[\"train_loss\"])\n",
    "    all_histories[\"val_loss\"].append(history[\"val_loss\"])\n",
    "    all_histories[\"train_acc\"].append(history[\"train_acc\"])\n",
    "    all_histories[\"val_acc\"].append(history[\"val_acc\"])\n",
    "\n",
    "    # ---- Final Test ----\n",
    "    student_model.load_state_dict(best_model_state)\n",
    "    acc, f1, prec, recall = evaluate_student(student_model, test_loader, device)\n",
    "\n",
    "    results[\"accuracy\"].append(acc)\n",
    "    results[\"f1\"].append(f1)\n",
    "    results[\"precision\"].append(prec)\n",
    "    results[\"recall\"].append(recall)\n",
    "\n",
    "    if val_acc > best_overall_accuracy:\n",
    "        best_overall_accuracy = val_acc\n",
    "        best_overall_model = student_model\n",
    "\n",
    "# ---- Save Best Model ----\n",
    "torch.save(best_overall_model.state_dict(), \"dermpGCN.pth\")\n",
    "print(f\"\\nBest Val Accuracy Model Saved (Acc={best_overall_accuracy:.4f})\")\n",
    "\n",
    "# ---- Summary ----\n",
    "print(\"\\n--- Final Evaluation Across Seeds ---\")\n",
    "for metric in results:\n",
    "    print(f\"{metric.capitalize()}: {np.mean(results[metric]):.4f} ¬± {np.std(results[metric]):.4f}\")\n",
    "\n",
    "# ---- PLOT AVERAGED TRAINING CURVES ----\n",
    "plot_average_training_curves(all_histories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f60bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_training_curves(all_histories, save_path=\"averaged_training_curves.png\"):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # ---- Set global bold font ----\n",
    "    plt.rcParams['font.weight'] = 'bold'\n",
    "    plt.rcParams['axes.labelweight'] = 'bold'\n",
    "    plt.rcParams['axes.titleweight'] = 'bold'\n",
    "    plt.rcParams['xtick.labelsize'] = 12\n",
    "    plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "    # ---- FIXED: Pad histories to the same length ----\n",
    "    max_epochs = max(len(h) for h in all_histories[\"train_loss\"])\n",
    "    \n",
    "    def pad_history(history_list, max_len):\n",
    "        \"\"\"Pad each history to max_len using the last value\"\"\"\n",
    "        padded = []\n",
    "        for hist in history_list:\n",
    "            if len(hist) < max_len:\n",
    "                # Pad with the last value\n",
    "                padded.append(hist + [hist[-1]] * (max_len - len(hist)))\n",
    "            else:\n",
    "                padded.append(hist)\n",
    "        return np.array(padded)\n",
    "    \n",
    "    train_loss = pad_history(all_histories[\"train_loss\"], max_epochs)\n",
    "    val_loss = pad_history(all_histories[\"val_loss\"], max_epochs)\n",
    "    train_acc = pad_history(all_histories[\"train_acc\"], max_epochs)\n",
    "    val_acc = pad_history(all_histories[\"val_acc\"], max_epochs)\n",
    "\n",
    "    epochs = np.arange(1, max_epochs + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # -------- Loss subplot --------\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    plt.plot(epochs, train_loss.mean(axis=0), label=\"Train Loss\")\n",
    "    plt.fill_between(\n",
    "        epochs,\n",
    "        train_loss.mean(axis=0) - train_loss.std(axis=0),\n",
    "        train_loss.mean(axis=0) + train_loss.std(axis=0),\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    plt.plot(epochs, val_loss.mean(axis=0), label=\"Validation Loss\")\n",
    "    plt.fill_between(\n",
    "        epochs,\n",
    "        val_loss.mean(axis=0) - val_loss.std(axis=0),\n",
    "        val_loss.mean(axis=0) + val_loss.std(axis=0),\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Epochs\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"Loss\", fontweight=\"bold\")\n",
    "    plt.title(\"Training and Validation Loss (Averaged Across Runs)\", fontweight=\"bold\")\n",
    "    plt.legend()\n",
    "\n",
    "    # -------- Accuracy subplot --------\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    plt.plot(epochs, train_acc.mean(axis=0), label=\"Train Accuracy\")\n",
    "    plt.fill_between(\n",
    "        epochs,\n",
    "        train_acc.mean(axis=0) - train_acc.std(axis=0),\n",
    "        train_acc.mean(axis=0) + train_acc.std(axis=0),\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    plt.plot(epochs, val_acc.mean(axis=0), label=\"Validation Accuracy\")\n",
    "    plt.fill_between(\n",
    "        epochs,\n",
    "        val_acc.mean(axis=0) - val_acc.std(axis=0),\n",
    "        val_acc.mean(axis=0) + val_acc.std(axis=0),\n",
    "        alpha=0.25\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Epochs\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"Accuracy\", fontweight=\"bold\")\n",
    "    plt.title(\"Training and Validation Accuracy (Averaged Across Runs)\", fontweight=\"bold\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ---- SAVE AT 650 DPI ----\n",
    "    plt.savefig(save_path, dpi=650, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_average_training_curves(all_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29981971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. FUNCTION TO PARSE ONE LOG FILE\n",
    "# ------------------------------------------------------------\n",
    "def parse_log(path):\n",
    "    metrics = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "    }\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            # Train loss + acc\n",
    "            m_train = re.search(\n",
    "                r\"Epoch\\s+(\\d+):\\s+Train Loss:\\s+([0-9.]+),\\s+Train Acc:\\s+([0-9.]+)\",\n",
    "                line\n",
    "            )\n",
    "            if m_train:\n",
    "                metrics[\"epoch\"].append(int(m_train.group(1)))\n",
    "                metrics[\"train_loss\"].append(float(m_train.group(2)))\n",
    "                metrics[\"train_acc\"].append(float(m_train.group(3)))\n",
    "                continue\n",
    "\n",
    "            # Val loss + acc\n",
    "            m_val = re.search(\n",
    "                r\"Epoch\\s+(\\d+):\\s+Val Loss:\\s+([0-9.]+),\\s+Val Acc:\\s+([0-9.]+)\",\n",
    "                line\n",
    "            )\n",
    "            if m_val:\n",
    "                metrics[\"val_loss\"].append(float(m_val.group(2)))\n",
    "                metrics[\"val_acc\"].append(float(m_val.group(3)))\n",
    "                continue\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. LOAD BOTH SEEDS\n",
    "# ------------------------------------------------------------\n",
    "log_files = {\n",
    "    \"42\": r\"C:\\Users\\User\\MDY Research\\With Augmentation\\Concatenation\\Adasyn\\seed_42.txt\",\n",
    "    \"569\": r\"C:\\Users\\User\\MDY Research\\With Augmentation\\Concatenation\\Adasyn\\seed_569.txt\",\n",
    "}\n",
    "\n",
    "histories = {}\n",
    "\n",
    "for seed, path in log_files.items():\n",
    "    histories[seed] = parse_log(path)\n",
    "    print(f\"Seed {seed}: {len(histories[seed]['epoch'])} epochs loaded\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. ALIGN EPOCHS ‚Äî truncate to minimum run length\n",
    "# ------------------------------------------------------------\n",
    "min_epochs = min(len(h[\"epoch\"]) for h in histories.values())\n",
    "print(f\"\\nUsing {min_epochs} epochs (minimum across seeds)\")\n",
    "\n",
    "seed_ids = sorted(histories.keys())\n",
    "num_seeds = len(seed_ids)\n",
    "\n",
    "train_loss = np.zeros((num_seeds, min_epochs))\n",
    "val_loss   = np.zeros((num_seeds, min_epochs))\n",
    "train_acc  = np.zeros((num_seeds, min_epochs))\n",
    "val_acc    = np.zeros((num_seeds, min_epochs))\n",
    "\n",
    "for i, sid in enumerate(seed_ids):\n",
    "    h = histories[sid]\n",
    "    train_loss[i] = np.array(h[\"train_loss\"][:min_epochs])\n",
    "    val_loss[i]   = np.array(h[\"val_loss\"][:min_epochs])\n",
    "    train_acc[i]  = np.array(h[\"train_acc\"][:min_epochs])\n",
    "    val_acc[i]    = np.array(h[\"val_acc\"][:min_epochs])\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. COMPUTE MEANS & STANDARD DEVIATIONS\n",
    "# ------------------------------------------------------------\n",
    "tl_mean, tl_std = train_loss.mean(0), train_loss.std(0)\n",
    "vl_mean, vl_std = val_loss.mean(0),   val_loss.std(0)\n",
    "\n",
    "ta_mean, ta_std = train_acc.mean(0),  train_acc.std(0)\n",
    "va_mean, va_std = val_acc.mean(0),    val_acc.std(0)\n",
    "\n",
    "epochs = np.arange(1, min_epochs + 1)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. PLOT COMBINED FIGURE (LOSS + ACCURACY)\n",
    "# ------------------------------------------------------------\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss subplot\n",
    "ax1.plot(epochs, tl_mean, label=\"Train Loss\", linewidth=2)\n",
    "ax1.fill_between(epochs, tl_mean - tl_std, tl_mean + tl_std, alpha=0.25)\n",
    "\n",
    "ax1.plot(epochs, vl_mean, label=\"Validation Loss\", linewidth=2)\n",
    "ax1.fill_between(epochs, vl_mean - vl_std, vl_mean + vl_std, alpha=0.25)\n",
    "\n",
    "ax1.set_xlabel(\"Epochs\", fontweight=\"bold\")\n",
    "ax1.set_ylabel(\"Loss\", fontweight=\"bold\")\n",
    "ax1.set_title(\"Training and Validation Loss (Averaged Across Seeds)\", fontweight=\"bold\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy subplot\n",
    "ax2.plot(epochs, ta_mean, label=\"Train Accuracy\", linewidth=2)\n",
    "ax2.fill_between(epochs, ta_mean - ta_std, ta_mean + ta_std, alpha=0.25)\n",
    "\n",
    "ax2.plot(epochs, va_mean, label=\"Validation Accuracy\", linewidth=2)\n",
    "ax2.fill_between(epochs, va_mean - va_std, va_mean + va_std, alpha=0.25)\n",
    "\n",
    "ax2.set_xlabel(\"Epochs\", fontweight=\"bold\")\n",
    "ax2.set_ylabel(\"Accuracy\", fontweight=\"bold\")\n",
    "ax2.set_title(\"Training and Validation Accuracy (Averaged Across Seeds)\", fontweight=\"bold\")\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_curves_from_logs.png\", dpi=650, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Saved: training_curves_from_logs.png\")\n",
    "print(f\"üìä Plotted {min_epochs} epochs from seeds: {', '.join(seed_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132104d7",
   "metadata": {},
   "source": [
    "# Parse Log Files and Create Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e445513-187f-4d9a-a981-8a88908ab80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Ensure the teacher model is in eval mode\n",
    "teacher_model.eval()\n",
    "\n",
    "# Collect true labels and predictions\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, metas, labels in test_loader:\n",
    "        images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "\n",
    "        outputs = teacher_model(images, metas)\n",
    "        probs = F.softmax(outputs, dim=1) if outputs.dim() == 2 else outputs\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# Compute classification report\n",
    "class_report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
    "\n",
    "# Compute normalized confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds, normalize=\"true\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(class_report)\n",
    "\n",
    "# Display confusion matrix (Blues colormap)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\".2f\", xticklabels=class_names, yticklabels=class_names, cbar=True)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot ROC-AUC curve for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    fpr, tpr, _ = roc_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")  # Diagonal line for reference\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC-AUC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot Precision-Recall Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    precision, recall, _ = precision_recall_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{class_name}\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the best model\n",
    "best_model = EarlyFusionWithGCN(input_dim_meta, num_classes).to(device)\n",
    "best_model.load_state_dict(torch.load(\"dermpGCN.pth\"))\n",
    "best_model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, metas, labels in test_loader:\n",
    "        images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "        batch_indices = torch.arange(metas.size(0)).to(device).long()\n",
    "        outputs = student_model(images, metas, batch_indices)        \n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# Compute classification report\n",
    "class_report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
    "\n",
    "# Compute normalized confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds, normalize=\"true\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(class_report)\n",
    "\n",
    "# Display confusion matrix (black and white)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"gray\", fmt=\".2f\", xticklabels=class_names, yticklabels=class_names, cbar=True)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot ROC-AUC curve for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    fpr, tpr, _ = roc_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")  # Diagonal line for reference\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC-AUC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Optional: Compute and plot Precision-Recall Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    precision, recall, _ = precision_recall_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{class_name}\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
