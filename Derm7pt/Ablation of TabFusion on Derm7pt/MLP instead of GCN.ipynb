{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1cf7d-e12a-469e-b3c6-c37dee98db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# DERM7PT DATA LOADER FOR TRAINING NOTEBOOKS\n",
    "# =========================================================\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# =========================================================\n",
    "# PATHS TO PREPROCESSED DATA\n",
    "# =========================================================\n",
    "PREPROCESSED_DIR = r\"augmented\"\n",
    "\n",
    "TRAIN_CSV = os.path.join(PREPROCESSED_DIR, \"train_metadata_final.csv\")\n",
    "VAL_CSV   = os.path.join(PREPROCESSED_DIR, \"val_metadata_final.csv\")\n",
    "TEST_CSV  = os.path.join(PREPROCESSED_DIR, \"test_metadata_final.csv\")\n",
    "\n",
    "INFO_PATH = os.path.join(PREPROCESSED_DIR, \"preprocessing_info.json\")\n",
    "\n",
    "# =========================================================\n",
    "# LOAD PREPROCESSED DATA\n",
    "# =========================================================\n",
    "print(\"Loading preprocessed Derm7pt data...\")\n",
    "\n",
    "# Load CSVs\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df   = pd.read_csv(VAL_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Load preprocessing info\n",
    "with open(INFO_PATH, \"r\") as f:\n",
    "    preprocessing_info = json.load(f)\n",
    "\n",
    "categorical_cols = preprocessing_info[\"categorical_cols\"]\n",
    "label_mapping = preprocessing_info[\"label_mapping\"]\n",
    "\n",
    "# Extract class names from label_mapping (sorted by label index)\n",
    "class_names = [k for k, v in sorted(label_mapping.items(), key=lambda x: x[1])]\n",
    "\n",
    "print(f\"\\nâœ… Training samples:   {len(train_df)}\")\n",
    "print(f\"âœ… Validation samples: {len(val_df)}\")\n",
    "print(f\"âœ… Test samples:       {len(test_df)}\")\n",
    "print(f\"\\nLabel mapping: {label_mapping}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# =========================================================\n",
    "# EXTRACT FEATURES AND LABELS\n",
    "# =========================================================\n",
    "def extract_features(df):\n",
    "    \"\"\"Extract image paths, metadata features, and labels from dataframe\"\"\"\n",
    "    img_paths = df[\"ImagePath\"].values\n",
    "    labels = df[\"label\"].values\n",
    "    \n",
    "    # Metadata features (all columns except ImagePath and label)\n",
    "    metadata_cols = [col for col in df.columns if col not in [\"ImagePath\", \"label\"]]\n",
    "    metadata = df[metadata_cols].values\n",
    "    \n",
    "    return img_paths, metadata, labels\n",
    "\n",
    "X_train_img, X_train_meta, y_train = extract_features(train_df)\n",
    "X_val_img, X_val_meta, y_val       = extract_features(val_df)\n",
    "X_test_img, X_test_meta, y_test    = extract_features(test_df)\n",
    "\n",
    "num_classes = len(label_mapping)\n",
    "print(f\"\\nNumber of classes: {num_classes}\")\n",
    "\n",
    "# Get input dimensions\n",
    "non_feature_cols = [\"label\", \"ImagePath\"]\n",
    "X_train_meta_df = train_df.drop(columns=non_feature_cols)\n",
    "input_dim_meta = X_train_meta_df.shape[1]\n",
    "print(f\"Metadata input dimension: {input_dim_meta}\")\n",
    "\n",
    "# =========================================================\n",
    "# PYTORCH DATASET CLASS\n",
    "# =========================================================\n",
    "class Derm7ptDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for Derm7pt with images + metadata\n",
    "    \"\"\"\n",
    "    def __init__(self, img_paths, metadata, labels, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.metadata = metadata\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.img_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            # Fallback to black image if loading fails\n",
    "            print(f\"Warning: Failed to load {img_path}, using placeholder\")\n",
    "            image = Image.new(\"RGB\", (224, 224), color=\"black\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get metadata and label\n",
    "        metadata = self.metadata[idx].astype(np.float32)\n",
    "        label = int(self.labels[idx])\n",
    "        \n",
    "        return image, metadata, label\n",
    "\n",
    "# =========================================================\n",
    "# DATA TRANSFORMS\n",
    "# =========================================================\n",
    "# Training transforms (with augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# =========================================================\n",
    "# CREATE DATASETS\n",
    "# =========================================================\n",
    "train_dataset = Derm7ptDataset(X_train_img, X_train_meta, y_train, transform=train_transform)\n",
    "val_dataset   = Derm7ptDataset(X_val_img, X_val_meta, y_val, transform=val_test_transform)\n",
    "test_dataset  = Derm7ptDataset(X_test_img, X_test_meta, y_test, transform=val_test_transform)\n",
    "\n",
    "print(f\"\\nâœ… Created PyTorch Datasets\")\n",
    "print(f\"   - Train: {len(train_dataset)} samples\")\n",
    "print(f\"   - Val:   {len(val_dataset)} samples\")\n",
    "print(f\"   - Test:  {len(test_dataset)} samples\")\n",
    "\n",
    "# =========================================================\n",
    "# CREATE DATALOADERS\n",
    "# =========================================================\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Set to 0 for Windows\n",
    "    pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Created DataLoaders (batch_size={BATCH_SIZE})\")\n",
    "print(f\"   - Train batches: {len(train_loader)}\")\n",
    "print(f\"   - Val batches:   {len(val_loader)}\")\n",
    "print(f\"   - Test batches:  {len(test_loader)}\")\n",
    "\n",
    "# =========================================================\n",
    "# EXAMPLE: TEST LOADING A BATCH\n",
    "# =========================================================\n",
    "print(\"\\nðŸ” Testing batch loading...\")\n",
    "for images, metadata, labels in train_loader:\n",
    "    print(f\"   - Image batch shape:    {images.shape}\")\n",
    "    print(f\"   - Metadata batch shape: {metadata.shape}\")\n",
    "    print(f\"   - Labels batch shape:   {labels.shape}\")\n",
    "    break\n",
    "\n",
    "print(\"\\nâœ… Derm7pt data loading complete! Ready for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5bf25-69d0-4003-ba73-e17a09b30154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_cluster import knn_graph\n",
    "import timm\n",
    "\n",
    "class EarlyFusionWithMLPMeta(nn.Module):\n",
    "    def __init__(self, input_dim_meta, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # === Pure MLP encoder for metadata ===\n",
    "        self.meta_embed = nn.Sequential(\n",
    "            nn.Linear(input_dim_meta, 64 * 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64 * 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # Reduce to 32D for metaâ†’image\n",
    "        self.meta_reduce = nn.Linear(64 * 64, 32)\n",
    "\n",
    "        # === Metadata â†’ pseudo-image ===\n",
    "        self.meta_to_image = nn.Sequential(\n",
    "            nn.Linear(32, 56 * 56),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(56 * 56),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # === MobileViT backbone (same as original) ===\n",
    "        self.mobilevit = timm.create_model(\"mobilevit_s.cvnets_in1k\", pretrained=True, num_classes=0)\n",
    "\n",
    "        stem_conv = self.mobilevit.stem.conv\n",
    "        new_conv = nn.Conv2d(4, stem_conv.out_channels,\n",
    "                             kernel_size=stem_conv.kernel_size,\n",
    "                             stride=stem_conv.stride,\n",
    "                             padding=stem_conv.padding)\n",
    "        with torch.no_grad():\n",
    "            new_conv.weight[:, :3] = stem_conv.weight\n",
    "            new_conv.weight[:, 3:] = stem_conv.weight.mean(dim=1, keepdim=True) * 0.1\n",
    "        self.mobilevit.stem.conv = new_conv\n",
    "\n",
    "        self.mobilevit.stages = nn.Sequential(*list(self.mobilevit.stages.children())[:4])\n",
    "        self.mobilevit.final_conv = nn.Identity()\n",
    "        self.mobilevit.head = nn.Identity()\n",
    "\n",
    "        self.post_conv = nn.Sequential(\n",
    "            nn.Conv2d(128, 160, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, meta, batch_idx=None):\n",
    "        B = meta.size(0)\n",
    "\n",
    "        # === MLP metadata encoder ===\n",
    "        meta_emb = self.meta_embed(meta)          # [B,4096]\n",
    "        meta_emb = self.meta_reduce(meta_emb)     # [B,32]\n",
    "\n",
    "        # === metadata â†’ pseudo-image ===\n",
    "        meta_img = self.meta_to_image(meta_emb).view(B, 1, 56, 56)\n",
    "        meta_img = F.interpolate(meta_img, size=(224, 224), mode='bilinear')\n",
    "\n",
    "        # === early fusion ===\n",
    "        x = torch.cat([img, meta_img], dim=1)\n",
    "\n",
    "        # === MobileViT ===\n",
    "        x = self.mobilevit.stem(x)\n",
    "        x = self.mobilevit.stages(x)\n",
    "        x = self.post_conv(x)\n",
    "        x = self.pool(x).view(B, -1)\n",
    "\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EarlyFusionWithMLPMeta(input_dim_meta, num_classes).to(device)\n",
    "\n",
    "dummy_img = torch.randn(batch_size, 3, 224, 224).to(device)\n",
    "dummy_meta = torch.randn(batch_size, input_dim_meta).to(device)\n",
    "dummy_batch_idx = torch.arange(batch_size).to(device)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=[dummy_img, dummy_meta, dummy_batch_idx],\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    depth=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17147dbc-c29c-491e-a452-955d9e5f1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# =========================================================\n",
    "# Utility Functions\n",
    "# =========================================================\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# =========================================================\n",
    "# Training Function\n",
    "# =========================================================\n",
    "def train_model(model, train_loader, val_loader, device, epochs=100, patience=5):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, verbose=True)\n",
    "    \n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "        \n",
    "        for images, metadata, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images, metadata, labels = images.to(device), metadata.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, metadata)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_accuracy = correct / total\n",
    "        history[\"train_loss\"].append(train_loss / len(train_loader))\n",
    "        history[\"train_acc\"].append(train_accuracy)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, metadata, labels in val_loader:\n",
    "                images, metadata, labels = images.to(device), metadata.to(device), labels.to(device)\n",
    "                outputs = model(images, metadata)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        val_accuracy = correct / total\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        history[\"val_loss\"].append(avg_val_loss)\n",
    "        history[\"val_acc\"].append(val_accuracy)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss={history['train_loss'][-1]:.4f}, Train Acc={train_accuracy:.4f}\")\n",
    "        print(f\"           Val Loss={avg_val_loss:.4f}, Val Acc={val_accuracy:.4f}\")\n",
    "        \n",
    "        # Early Stopping\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "    \n",
    "    return best_model_state, history, best_val_accuracy\n",
    "\n",
    "# =========================================================\n",
    "# Evaluation Function\n",
    "# =========================================================\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, metadata, labels in test_loader:\n",
    "            images, metadata = images.to(device), metadata.to(device)\n",
    "            outputs = model(images, metadata)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    \n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    \n",
    "    return accuracy, f1, precision, recall\n",
    "\n",
    "# =========================================================\n",
    "# Multi-Seed Training\n",
    "# =========================================================\n",
    "seeds = [42, 123, 569]\n",
    "best_overall_model = None\n",
    "best_overall_accuracy = 0.0\n",
    "\n",
    "results = {\"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": []}\n",
    "all_histories = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training with Seed {seed}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    set_seed(seed)\n",
    "    \n",
    "    model = EarlyFusionWithMLPMeta(input_dim_meta=input_dim_meta, num_classes=num_classes).to(device)\n",
    "    \n",
    "    best_model_state, history, val_acc = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        epochs=100,\n",
    "        patience=5\n",
    "    )\n",
    "    \n",
    "    # Store history\n",
    "    all_histories[\"train_loss\"].append(history[\"train_loss\"])\n",
    "    all_histories[\"val_loss\"].append(history[\"val_loss\"])\n",
    "    all_histories[\"train_acc\"].append(history[\"train_acc\"])\n",
    "    all_histories[\"val_acc\"].append(history[\"val_acc\"])\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.load_state_dict(best_model_state)\n",
    "    acc, f1, prec, recall = evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    results[\"accuracy\"].append(acc)\n",
    "    results[\"f1\"].append(f1)\n",
    "    results[\"precision\"].append(prec)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    if val_acc > best_overall_accuracy:\n",
    "        best_overall_accuracy = val_acc\n",
    "        best_overall_model = best_model_state\n",
    "\n",
    "# Save best model\n",
    "torch.save(best_overall_model, \"Derm7ptMLPFusion_best.pth\")\n",
    "print(f\"\\nâœ… Best model saved with Val Accuracy: {best_overall_accuracy:.4f}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Results Across All Seeds\")\n",
    "print(\"=\"*60)\n",
    "for metric in results:\n",
    "    mean_val = np.mean(results[metric])\n",
    "    std_val = np.std(results[metric])\n",
    "    print(f\"{metric.capitalize()}: {mean_val:.4f} Â± {std_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Results Across All Seeds\")\n",
    "print(\"=\"*60)\n",
    "for metric in results:\n",
    "    mean_val = np.mean(results[metric])\n",
    "    std_val = np.std(results[metric])\n",
    "    print(f\"{metric.capitalize()}: {mean_val:.4f} Â± {std_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_average_training_curves(all_histories, save_path=\"MLPFusion_training_curves.png\"):\n",
    "    plt.rcParams['font.weight'] = 'bold'\n",
    "    plt.rcParams['axes.labelweight'] = 'bold'\n",
    "    plt.rcParams['axes.titleweight'] = 'bold'\n",
    "    plt.rcParams['xtick.labelsize'] = 12\n",
    "    plt.rcParams['ytick.labelsize'] = 12\n",
    "    \n",
    "    # Find minimum length\n",
    "    min_len = min(len(h) for h in all_histories[\"train_loss\"])\n",
    "    \n",
    "    # Truncate to same length\n",
    "    train_loss = np.array([h[:min_len] for h in all_histories[\"train_loss\"]])\n",
    "    val_loss = np.array([h[:min_len] for h in all_histories[\"val_loss\"]])\n",
    "    train_acc = np.array([h[:min_len] for h in all_histories[\"train_acc\"]])\n",
    "    val_acc = np.array([h[:min_len] for h in all_histories[\"val_acc\"]])\n",
    "    \n",
    "    epochs = np.arange(1, min_len + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss.mean(axis=0), label=\"Train Loss\")\n",
    "    plt.fill_between(epochs,\n",
    "                     train_loss.mean(axis=0) - train_loss.std(axis=0),\n",
    "                     train_loss.mean(axis=0) + train_loss.std(axis=0),\n",
    "                     alpha=0.25)\n",
    "    plt.plot(epochs, val_loss.mean(axis=0), label=\"Validation Loss\")\n",
    "    plt.fill_between(epochs,\n",
    "                     val_loss.mean(axis=0) - val_loss.std(axis=0),\n",
    "                     val_loss.mean(axis=0) + val_loss.std(axis=0),\n",
    "                     alpha=0.25)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss - MLP Fusion\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_acc.mean(axis=0), label=\"Train Accuracy\")\n",
    "    plt.fill_between(epochs,\n",
    "                     train_acc.mean(axis=0) - train_acc.std(axis=0),\n",
    "                     train_acc.mean(axis=0) + train_acc.std(axis=0),\n",
    "                     alpha=0.25)\n",
    "    plt.plot(epochs, val_acc.mean(axis=0), label=\"Validation Accuracy\")\n",
    "    plt.fill_between(epochs,\n",
    "                     val_acc.mean(axis=0) - val_acc.std(axis=0),\n",
    "                     val_acc.mean(axis=0) + val_acc.std(axis=0),\n",
    "                     alpha=0.25)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy - MLP Fusion\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=650, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "plot_average_training_curves(all_histories)\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "model = EarlyFusionWithMLPMeta(input_dim_meta=input_dim_meta, num_classes=num_classes, backbone='mobilevit_xxs').to(device)\n",
    "model.load_state_dict(best_overall_model)\n",
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, metadata, labels in test_loader:\n",
    "        images, metadata = images.to(device), metadata.to(device)\n",
    "        outputs = model(images, metadata)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix - MLP Fusion', fontweight='bold')\n",
    "plt.ylabel('True Label', fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e10ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "# =========================================================\n",
    "# Parameter Count\n",
    "# =========================================================\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "params_m = count_parameters(model) / 1e6\n",
    "print(f\"Total Trainable Parameters: {params_m:.3f} M\")\n",
    "\n",
    "# =========================================================\n",
    "# FLOPs with Fusion Wrapper\n",
    "# =========================================================\n",
    "class FusionWrapper(nn.Module):\n",
    "    def __init__(self, model, meta_dim):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.meta_dim = meta_dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        dummy_meta = torch.randn(B, self.meta_dim, device=x.device)\n",
    "        return self.model(x, dummy_meta)\n",
    "\n",
    "wrapped_model = FusionWrapper(model, input_dim_meta)\n",
    "\n",
    "with torch.no_grad():\n",
    "    flops, params = get_model_complexity_info(\n",
    "        wrapped_model,\n",
    "        (3, 224, 224),\n",
    "        as_strings=False,\n",
    "        print_per_layer_stat=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "flops_g = flops / 1e9\n",
    "print(f\"FLOPs: {flops_g:.3f} GFLOPs\")\n",
    "\n",
    "# =========================================================\n",
    "# GPU Latency\n",
    "# =========================================================\n",
    "def measure_gpu_latency(model, meta_dim, device, runs=200, warmup=30):\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA not available\")\n",
    "        return None, None\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    dummy_img = torch.randn(1, 3, 224, 224, device=device)\n",
    "    dummy_meta = torch.randn(1, meta_dim, device=device)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(warmup):\n",
    "        _ = model(dummy_img, dummy_meta)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # Measure\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "    times = []\n",
    "    \n",
    "    for _ in range(runs):\n",
    "        start_event.record()\n",
    "        _ = model(dummy_img, dummy_meta)\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        times.append(start_event.elapsed_time(end_event))\n",
    "    \n",
    "    times = np.array(times)\n",
    "    avg_latency_ms = times.mean()\n",
    "    std_latency_ms = times.std()\n",
    "    fps = 1000.0 / avg_latency_ms\n",
    "    \n",
    "    print(f\"GPU Latency: {avg_latency_ms:.3f} Â± {std_latency_ms:.3f} ms  |  FPS: {fps:.1f} (avg over {runs} runs)\")\n",
    "    return avg_latency_ms, std_latency_ms\n",
    "\n",
    "# =========================================================\n",
    "# CPU Latency\n",
    "# =========================================================\n",
    "def measure_cpu_latency(model, meta_dim, runs=200, warmup=30):\n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "    \n",
    "    dummy_img = torch.randn(1, 3, 224, 224)\n",
    "    dummy_meta = torch.randn(1, meta_dim)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(warmup):\n",
    "        _ = model(dummy_img, dummy_meta)\n",
    "    \n",
    "    # Measure\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        start = time.time()\n",
    "        _ = model(dummy_img, dummy_meta)\n",
    "        end = time.time()\n",
    "        times.append((end - start) * 1000)\n",
    "    \n",
    "    times = np.array(times)\n",
    "    avg_latency_ms = times.mean()\n",
    "    std_latency_ms = times.std()\n",
    "    fps = 1000.0 / avg_latency_ms\n",
    "    print(f\"CPU Latency: {avg_latency_ms:.3f} Â± {std_latency_ms:.3f} ms  |  FPS: {fps:.1f} (avg over {runs} runs)\")\n",
    "    return avg_latency_ms, std_latency_ms\n",
    "\n",
    "# =========================================================\n",
    "# Run Benchmarks\n",
    "# =========================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Complexity Analysis - MLP Fusion\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "gpu_latency, gpu_std = measure_gpu_latency(model, input_dim_meta, device)\n",
    "cpu_latency, cpu_std = measure_cpu_latency(model, input_dim_meta)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Parameters: {params_m:.3f} M\")\n",
    "print(f\"FLOPs: {flops_g:.3f} GFLOPs\")\n",
    "if gpu_latency:\n",
    "    gpu_fps = 1000.0 / gpu_latency\n",
    "    print(f\"GPU Latency: {gpu_latency:.3f} Â± {gpu_std:.3f} ms  |  FPS: {gpu_fps:.1f}\")\n",
    "cpu_fps = 1000.0 / cpu_latency\n",
    "print(f\"CPU Latency: {cpu_latency:.3f} Â± {cpu_std:.3f} ms  |  FPS: {cpu_fps:.1f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
