{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1cf7d-e12a-469e-b3c6-c37dee98db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# DERM7PT DATA LOADER FOR TRAINING NOTEBOOKS\n",
    "# =========================================================\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# =========================================================\n",
    "# PATHS TO PREPROCESSED DATA\n",
    "# =========================================================\n",
    "PREPROCESSED_DIR = r\"augmented\"\n",
    "\n",
    "TRAIN_CSV = os.path.join(PREPROCESSED_DIR, \"train_metadata_final.csv\")\n",
    "VAL_CSV   = os.path.join(PREPROCESSED_DIR, \"val_metadata_final.csv\")\n",
    "TEST_CSV  = os.path.join(PREPROCESSED_DIR, \"test_metadata_final.csv\")\n",
    "\n",
    "INFO_PATH = os.path.join(PREPROCESSED_DIR, \"preprocessing_info.json\")\n",
    "\n",
    "# =========================================================\n",
    "# LOAD PREPROCESSED DATA\n",
    "# =========================================================\n",
    "print(\"Loading preprocessed Derm7pt data...\")\n",
    "\n",
    "# Load CSVs\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df   = pd.read_csv(VAL_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Load preprocessing info\n",
    "with open(INFO_PATH, \"r\") as f:\n",
    "    preprocessing_info = json.load(f)\n",
    "\n",
    "categorical_cols = preprocessing_info[\"categorical_cols\"]\n",
    "label_mapping = preprocessing_info[\"label_mapping\"]\n",
    "\n",
    "# Extract class names from label_mapping (sorted by label index)\n",
    "class_names = [k for k, v in sorted(label_mapping.items(), key=lambda x: x[1])]\n",
    "\n",
    "print(f\"\\nâœ… Training samples:   {len(train_df)}\")\n",
    "print(f\"âœ… Validation samples: {len(val_df)}\")\n",
    "print(f\"âœ… Test samples:       {len(test_df)}\")\n",
    "print(f\"\\nLabel mapping: {label_mapping}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# =========================================================\n",
    "# EXTRACT FEATURES AND LABELS\n",
    "# =========================================================\n",
    "def extract_features(df):\n",
    "    \"\"\"Extract image paths, metadata features, and labels from dataframe\"\"\"\n",
    "    img_paths = df[\"ImagePath\"].values\n",
    "    labels = df[\"label\"].values\n",
    "    \n",
    "    # Metadata features (all columns except ImagePath and label)\n",
    "    metadata_cols = [col for col in df.columns if col not in [\"ImagePath\", \"label\"]]\n",
    "    metadata = df[metadata_cols].values\n",
    "    \n",
    "    return img_paths, metadata, labels\n",
    "\n",
    "X_train_img, X_train_meta, y_train = extract_features(train_df)\n",
    "X_val_img, X_val_meta, y_val       = extract_features(val_df)\n",
    "X_test_img, X_test_meta, y_test    = extract_features(test_df)\n",
    "\n",
    "num_classes = len(label_mapping)\n",
    "print(f\"\\nNumber of classes: {num_classes}\")\n",
    "\n",
    "# Get input dimensions\n",
    "non_feature_cols = [\"label\", \"ImagePath\"]\n",
    "X_train_meta_df = train_df.drop(columns=non_feature_cols)\n",
    "input_dim_meta = X_train_meta_df.shape[1]\n",
    "print(f\"Metadata input dimension: {input_dim_meta}\")\n",
    "\n",
    "# =========================================================\n",
    "# PYTORCH DATASET CLASS\n",
    "# =========================================================\n",
    "class Derm7ptDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for Derm7pt with images + metadata\n",
    "    \"\"\"\n",
    "    def __init__(self, img_paths, metadata, labels, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.metadata = metadata\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.img_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            # Fallback to black image if loading fails\n",
    "            print(f\"Warning: Failed to load {img_path}, using placeholder\")\n",
    "            image = Image.new(\"RGB\", (224, 224), color=\"black\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get metadata and label\n",
    "        metadata = self.metadata[idx].astype(np.float32)\n",
    "        label = int(self.labels[idx])\n",
    "        \n",
    "        return image, metadata, label\n",
    "\n",
    "# =========================================================\n",
    "# DATA TRANSFORMS\n",
    "# =========================================================\n",
    "# Training transforms (with augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# =========================================================\n",
    "# CREATE DATASETS\n",
    "# =========================================================\n",
    "train_dataset = Derm7ptDataset(X_train_img, X_train_meta, y_train, transform=train_transform)\n",
    "val_dataset   = Derm7ptDataset(X_val_img, X_val_meta, y_val, transform=val_test_transform)\n",
    "test_dataset  = Derm7ptDataset(X_test_img, X_test_meta, y_test, transform=val_test_transform)\n",
    "\n",
    "print(f\"\\nâœ… Created PyTorch Datasets\")\n",
    "print(f\"   - Train: {len(train_dataset)} samples\")\n",
    "print(f\"   - Val:   {len(val_dataset)} samples\")\n",
    "print(f\"   - Test:  {len(test_dataset)} samples\")\n",
    "\n",
    "# =========================================================\n",
    "# CREATE DATALOADERS\n",
    "# =========================================================\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Set to 0 for Windows\n",
    "    pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Created DataLoaders (batch_size={BATCH_SIZE})\")\n",
    "print(f\"   - Train batches: {len(train_loader)}\")\n",
    "print(f\"   - Val batches:   {len(val_loader)}\")\n",
    "print(f\"   - Test batches:  {len(test_loader)}\")\n",
    "\n",
    "# =========================================================\n",
    "# EXAMPLE: TEST LOADING A BATCH\n",
    "# =========================================================\n",
    "print(\"\\nðŸ” Testing batch loading...\")\n",
    "for images, metadata, labels in train_loader:\n",
    "    print(f\"   - Image batch shape:    {images.shape}\")\n",
    "    print(f\"   - Metadata batch shape: {metadata.shape}\")\n",
    "    print(f\"   - Labels batch shape:   {labels.shape}\")\n",
    "    break\n",
    "\n",
    "print(\"\\nâœ… Derm7pt data loading complete! Ready for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38493ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_cluster import knn_graph\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# IMPROVED MODEL (A FIXED TO MATCH B'S BEHAVIOR)\n",
    "# =========================================================\n",
    "class EarlyFusionWithGCN(nn.Module):\n",
    "    def __init__(self, input_dim_meta, num_classes, k=8):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "\n",
    "        # --- GCN Layers ---\n",
    "        self.gcn1 = GCNConv(input_dim_meta, 64)\n",
    "        self.gcn2 = GCNConv(64, 32)\n",
    "        self.res_proj = nn.Linear(64, 32)\n",
    "\n",
    "        # --- metadata â†’ pseudo image ---\n",
    "        self.meta_to_image = nn.Sequential(\n",
    "            nn.Linear(32, 56 * 56),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(56 * 56),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # --- MobileViT backbone ---\n",
    "        self.mobilevit = timm.create_model(\n",
    "            \"mobilevit_s.cvnets_in1k\",\n",
    "            pretrained=True,\n",
    "            num_classes=0\n",
    "        )\n",
    "\n",
    "        # --- Modify first conv to accept 4 channels ---\n",
    "        stem_conv = self.mobilevit.stem.conv\n",
    "        new_conv = nn.Conv2d(\n",
    "            4, stem_conv.out_channels,\n",
    "            kernel_size=stem_conv.kernel_size,\n",
    "            stride=stem_conv.stride,\n",
    "            padding=stem_conv.padding,\n",
    "            bias=stem_conv.bias is not None\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # copy RGB weights\n",
    "            new_conv.weight[:, :3] = stem_conv.weight\n",
    "            # tiny weight for metadata channel\n",
    "            new_conv.weight[:, 3:] = stem_conv.weight.mean(dim=1, keepdim=True) * 0.1\n",
    "            # copy bias if exists\n",
    "            if stem_conv.bias is not None:\n",
    "                new_conv.bias = stem_conv.bias.clone()\n",
    "\n",
    "        self.mobilevit.stem.conv = new_conv\n",
    "\n",
    "        # keep only first 4 stages\n",
    "        self.mobilevit.stages = nn.Sequential(\n",
    "            *list(self.mobilevit.stages.children())[:4]\n",
    "        )\n",
    "        self.mobilevit.final_conv = nn.Identity()\n",
    "        self.mobilevit.head = nn.Identity()\n",
    "\n",
    "        # --- Post Conv ---\n",
    "        self.post_conv = nn.Sequential(\n",
    "            nn.Conv2d(128, 160, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # --- Classifier ---\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, meta, batch_idx):\n",
    "        B = meta.size(0)\n",
    "\n",
    "        # CORRECT: dynamic kNN graph WITHOUT self-loops\n",
    "        edge_index = knn_graph(meta, k=self.k, batch=batch_idx)\n",
    "\n",
    "        # GCN + residual\n",
    "        x1 = F.relu(self.gcn1(meta, edge_index))\n",
    "        x2 = F.relu(self.gcn2(x1, edge_index) + self.res_proj(x1))\n",
    "\n",
    "        # Metadata â†’ pseudo-image\n",
    "        meta_img = self.meta_to_image(x2).view(B, 1, 56, 56)\n",
    "        meta_img = F.interpolate(meta_img, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        # Early fusion (4 channels)\n",
    "        x = torch.cat([img, meta_img], dim=1)\n",
    "\n",
    "        # CNN forward\n",
    "        feats = self.mobilevit.stem(x)\n",
    "        feats = self.mobilevit.stages(feats)\n",
    "        feats = self.post_conv(feats)\n",
    "        feats = self.pool(feats).view(B, -1)\n",
    "\n",
    "        return self.classifier(feats)\n",
    "    \n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EarlyFusionWithGCN(input_dim_meta, num_classes).to(device)\n",
    "\n",
    "dummy_img = torch.randn(batch_size, 3, 224, 224).to(device)\n",
    "dummy_meta = torch.randn(batch_size, input_dim_meta).to(device)\n",
    "dummy_batch_idx = torch.arange(batch_size).to(device)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=[dummy_img, dummy_meta, dummy_batch_idx],\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    depth=3\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b27e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# Seed Utility\n",
    "# -----------------------------\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -----------------------------\n",
    "# Early Stopping Class\n",
    "# -----------------------------\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.best_accuracy = -np.inf\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss, val_acc, model):\n",
    "        # Monitor validation LOSS for early stopping (lower is better)\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif val_loss >= self.best_loss - self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience} (val_loss: {val_loss:.4f}, best: {self.best_loss:.4f})')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            if self.verbose:\n",
    "                print(f'âœ… Validation loss improved ({self.best_loss:.6f} --> {val_loss:.6f})')\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        \n",
    "        # Save checkpoint based on best ACCURACY\n",
    "        if val_acc > self.best_accuracy:\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "\n",
    "    def save_checkpoint(self, val_acc, model):\n",
    "        if self.verbose:\n",
    "            print(f'ðŸ’¾ Validation accuracy improved ({self.best_accuracy:.6f} --> {val_acc:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.best_accuracy = val_acc\n",
    "\n",
    "# -----------------------------\n",
    "# Training Function\n",
    "# -----------------------------\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    for images, meta, labels in pbar:\n",
    "        images, meta, labels = images.to(device), meta.to(device), labels.to(device)\n",
    "        batch_idx = torch.arange(meta.size(0), device=device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, meta, batch_idx)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss/total:.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return running_loss/len(train_loader), correct/total\n",
    "\n",
    "# -----------------------------\n",
    "# Validation Function\n",
    "# -----------------------------\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, meta, labels in val_loader:\n",
    "            images, meta, labels = images.to(device), meta.to(device), labels.to(device)\n",
    "            batch_idx = torch.arange(meta.size(0), device=device).long()\n",
    "            \n",
    "            outputs = model(images, meta, batch_idx)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss/len(val_loader), correct/total\n",
    "\n",
    "# -----------------------------\n",
    "# Training Loop with Scheduler and Checkpoint\n",
    "# -----------------------------\n",
    "def train_model_with_scheduler_and_checkpoint(\n",
    "    model, train_loader, val_loader, optimizer, criterion, device, \n",
    "    epochs=100, patience=5, scheduler_patience=3, checkpoint_dir='checkpoints'):\n",
    "    \n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=patience, \n",
    "        verbose=True,\n",
    "        path=checkpoint_path\n",
    "    )\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min',  # Monitor loss (lower is better)\n",
    "        patience=scheduler_patience, \n",
    "        verbose=True,\n",
    "        factor=0.1,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    best_model_epoch = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{epochs}')\n",
    "        \n",
    "        # Training phase\n",
    "        train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        # Update scheduler based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Early stopping check\n",
    "        early_stopping(val_loss, val_acc, model)\n",
    "        if val_acc > early_stopping.best_accuracy:\n",
    "            best_model_epoch = epoch + 1\n",
    "            \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"ðŸ›‘ Early stopping triggered (validation loss not improving)\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation Function\n",
    "# -----------------------------\n",
    "def evaluate_test_metrics(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, metas, labels in test_loader:\n",
    "            images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "            batch_idx = torch.arange(metas.size(0), device=device).long()\n",
    "            outputs = model(images, metas, batch_idx)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "# -----------------------------\n",
    "# Multi-Seed Training\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seeds = [42, 123, 569]  \n",
    "results = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1_score\": []\n",
    "}\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training with random seed: {seed}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    set_random_seed(seed)\n",
    "    \n",
    "    # Reinitialize model, optimizer, and criterion\n",
    "    model = EarlyFusionWithGCN(input_dim_meta, num_classes, k=8).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Train the model\n",
    "    model, history = train_model_with_scheduler_and_checkpoint(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=100,\n",
    "        patience=5,\n",
    "        scheduler_patience=3,\n",
    "        checkpoint_dir='checkpoints'\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    acc, precision, recall, f1 = evaluate_test_metrics(model, test_loader, device)\n",
    "    print(f\"\\nSeed {seed} Results:\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Save metrics\n",
    "    results[\"accuracy\"].append(acc)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"recall\"].append(recall)\n",
    "    results[\"f1_score\"].append(f1)\n",
    "    \n",
    "    # Update the best model\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "# =========================================================\n",
    "# SUMMARY OF RESULTS\n",
    "# =========================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FINAL RESULTS ACROSS ALL SEEDS\")\n",
    "print(f\"{'='*60}\")\n",
    "for metric, values in results.items():\n",
    "    avg = np.mean(values)\n",
    "    std_dev = np.std(values)\n",
    "    print(f\"{metric.replace('_', ' ').title():12s}: Mean={avg:.4f}, StdDev={std_dev:.4f}\")\n",
    "\n",
    "# Save best model\n",
    "torch.save(best_model_state, 'DermGCNImageMetadataNoKD_best.pth')\n",
    "print(f\"\\nâœ… Best model saved with accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df95cd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate the best model\n",
    "best_model = EarlyFusionWithGCN(input_dim_meta, num_classes, k=8).to(device)\n",
    "best_model.load_state_dict(torch.load('DermGCNImageMetadataNoKD_best.pth'))\n",
    "best_model.eval()\n",
    "\n",
    "# Test and generate classification report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def test(model, loader, device, desc=\"Testing\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, metas, labels in tqdm(loader, total=len(loader), desc=desc, unit=\"batch\"):\n",
    "            imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
    "            batch_idx = torch.arange(metas.size(0), device=device).long()\n",
    "            outputs = model(imgs, metas, batch_idx)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_preds\n",
    "\n",
    "# Run test\n",
    "true_labels, pred_labels = test(best_model, test_loader, device, desc=\"Evaluating on Test\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "report = classification_report(true_labels, pred_labels, target_names=class_names, digits=4)\n",
    "print(report)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(true_labels, pred_labels, normalize=\"true\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\".2f\",\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Normalized Count'})\n",
    "plt.xlabel(\"Predicted Label\", fontweight=\"bold\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontweight=\"bold\", fontsize=12)\n",
    "plt.title(\"Normalized Confusion Matrix - GCN with Image and Metadata (No KD)\", fontweight=\"bold\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381774b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_size = (3, 224, 224)\n",
    "\n",
    "def count_parameters(model, trainable_only=False):\n",
    "    if trainable_only:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "class GCNWrapper(nn.Module):\n",
    "    \"\"\"Wraps 2-input (img, meta) + batch_idx models for ptflops\"\"\"\n",
    "    def __init__(self, model, meta_dim):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.meta_dim = meta_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        dummy_meta = torch.randn(B, self.meta_dim).to(x.device)\n",
    "        batch_idx = torch.arange(B, device=x.device)\n",
    "        return self.model(x, dummy_meta, batch_idx)\n",
    "\n",
    "def compute_flops(model, meta_dim):\n",
    "    wrapper = GCNWrapper(model, meta_dim).to(device)\n",
    "    with torch.no_grad():\n",
    "        flops, _ = get_model_complexity_info(\n",
    "            wrapper,\n",
    "            image_size,\n",
    "            as_strings=False,\n",
    "            print_per_layer_stat=False,\n",
    "            verbose=False\n",
    "        )\n",
    "    return float(flops / 1e9)  # GFLOPs\n",
    "\n",
    "def measure_gpu_latency(model, meta_dim, runs=200, warmup=30):\n",
    "    if not torch.cuda.is_available():\n",
    "        return None, None, None\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    model.eval().to(device)\n",
    "\n",
    "    dummy_img = torch.randn(1, *image_size, device=device)\n",
    "    dummy_meta = torch.randn(1, meta_dim, device=device)\n",
    "    batch_idx = torch.arange(1, device=device)\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(warmup):\n",
    "        _ = model(dummy_img, dummy_meta, batch_idx)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    start_evt = torch.cuda.Event(enable_timing=True)\n",
    "    end_evt = torch.cuda.Event(enable_timing=True)\n",
    "    times = []\n",
    "\n",
    "    for _ in range(runs):\n",
    "        start_evt.record()\n",
    "        _ = model(dummy_img, dummy_meta, batch_idx)\n",
    "        end_evt.record()\n",
    "        torch.cuda.synchronize()\n",
    "        times.append(start_evt.elapsed_time(end_evt))  # ms\n",
    "\n",
    "    times = np.array(times)\n",
    "    mean = float(times.mean())\n",
    "    std = float(times.std())\n",
    "    fps = float(1000.0 / mean)\n",
    "    return mean, std, fps\n",
    "\n",
    "def measure_cpu_latency(model, meta_dim, runs=100, warmup=20):\n",
    "    model_cpu = model.cpu()\n",
    "    model_cpu.eval()\n",
    "\n",
    "    dummy_img = torch.randn(1, *image_size)\n",
    "    dummy_meta = torch.randn(1, meta_dim)\n",
    "    batch_idx = torch.arange(1)\n",
    "\n",
    "    for _ in range(warmup):\n",
    "        _ = model_cpu(dummy_img, dummy_meta, batch_idx)\n",
    "\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        start = time.perf_counter()\n",
    "        _ = model_cpu(dummy_img, dummy_meta, batch_idx)\n",
    "        end = time.perf_counter()\n",
    "        times.append((end - start) * 1000.0)\n",
    "\n",
    "    times = np.array(times)\n",
    "    mean = float(times.mean())\n",
    "    std = float(times.std())\n",
    "    fps = float(1000.0 / mean)\n",
    "    return mean, std, fps\n",
    "\n",
    "def benchmark_model(model, name, meta_dim):\n",
    "    \"\"\"Comprehensive model benchmarking\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Benchmarking: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    params_m = count_parameters(model, trainable_only=True) / 1e6\n",
    "    print(f\"Parameters: {params_m:.3f} M\")\n",
    "\n",
    "    flops_g = compute_flops(model, meta_dim)\n",
    "    print(f\"FLOPs: {flops_g:.3f} G\")\n",
    "\n",
    "    gpu_mean, gpu_std, gpu_fps = measure_gpu_latency(model, meta_dim)\n",
    "    if gpu_mean is not None:\n",
    "        print(f\"GPU Latency: {gpu_mean:.3f} Â± {gpu_std:.3f} ms  |  FPS: {gpu_fps:.1f}\")\n",
    "    else:\n",
    "        print(\"GPU Latency: N/A\")\n",
    "\n",
    "    cpu_mean, cpu_std, cpu_fps = measure_cpu_latency(model, meta_dim)\n",
    "    print(f\"CPU Latency: {cpu_mean:.3f} Â± {cpu_std:.3f} ms  |  FPS: {cpu_fps:.1f}\")\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"params_M\": params_m,\n",
    "        \"flops_G\": flops_g,\n",
    "        \"gpu_latency_mean_ms\": gpu_mean,\n",
    "        \"gpu_latency_std_ms\": gpu_std,\n",
    "        \"gpu_fps\": gpu_fps,\n",
    "        \"cpu_latency_mean_ms\": cpu_mean,\n",
    "        \"cpu_latency_std_ms\": cpu_std,\n",
    "        \"cpu_fps\": cpu_fps,\n",
    "    }\n",
    "\n",
    "# Benchmark the best model\n",
    "best_model = EarlyFusionWithGCN(input_dim_meta, num_classes, k=8)\n",
    "best_model.load_state_dict(torch.load(\"DermGCNImageMetadataNoKD_best.pth\", map_location=\"cpu\"))\n",
    "best_model.to(device).eval()\n",
    "\n",
    "results_benchmark = benchmark_model(best_model, \"GCN with Image and Metadata (No KD)\", input_dim_meta)\n",
    "print(\"\\nâœ… Complexity analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
