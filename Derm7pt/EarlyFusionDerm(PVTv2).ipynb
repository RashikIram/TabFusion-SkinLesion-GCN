{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1cf7d-e12a-469e-b3c6-c37dee98db7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T06:42:40.712786Z",
     "iopub.status.busy": "2025-04-05T06:42:40.712786Z",
     "iopub.status.idle": "2025-04-05T06:42:44.624019Z",
     "shell.execute_reply": "2025-04-05T06:42:44.624019Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# DERM7PT DATA LOADER FOR TRAINING NOTEBOOKS\n",
    "# =========================================================\n",
    "# Run this code in your training notebooks to load the preprocessed Derm7pt dataset\n",
    "# Make sure the preprocessing pipeline above has been executed first!\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# =========================================================\n",
    "# PATHS TO PREPROCESSED DATA\n",
    "# =========================================================\n",
    "PREPROCESSED_DIR = r\"augmented\"\n",
    "\n",
    "TRAIN_CSV = os.path.join(PREPROCESSED_DIR, \"train_metadata_final.csv\")\n",
    "VAL_CSV   = os.path.join(PREPROCESSED_DIR, \"val_metadata_final.csv\")\n",
    "TEST_CSV  = os.path.join(PREPROCESSED_DIR, \"test_metadata_final.csv\")\n",
    "\n",
    "INFO_PATH = os.path.join(PREPROCESSED_DIR, \"preprocessing_info.json\")\n",
    "\n",
    "# =========================================================\n",
    "# LOAD PREPROCESSED DATA\n",
    "# =========================================================\n",
    "print(\"Loading preprocessed Derm7pt data...\")\n",
    "\n",
    "# Load CSVs\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df   = pd.read_csv(VAL_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Load preprocessing info\n",
    "with open(INFO_PATH, \"r\") as f:\n",
    "    preprocessing_info = json.load(f)\n",
    "\n",
    "categorical_cols = preprocessing_info[\"categorical_cols\"]\n",
    "label_mapping = preprocessing_info[\"label_mapping\"]\n",
    "\n",
    "print(f\"\\n‚úÖ Training samples:   {len(train_df)}\")\n",
    "print(f\"‚úÖ Validation samples: {len(val_df)}\")\n",
    "print(f\"‚úÖ Test samples:       {len(test_df)}\")\n",
    "print(f\"\\nLabel mapping: {label_mapping}\")\n",
    "\n",
    "# =========================================================\n",
    "# EXTRACT FEATURES AND LABELS\n",
    "# =========================================================\n",
    "def extract_features(df):\n",
    "    \"\"\"Extract image paths, metadata features, and labels from dataframe\"\"\"\n",
    "    img_paths = df[\"ImagePath\"].values\n",
    "    labels = df[\"label\"].values\n",
    "    \n",
    "    # Metadata features (all columns except ImagePath and label)\n",
    "    metadata_cols = [col for col in df.columns if col not in [\"ImagePath\", \"label\"]]\n",
    "    metadata = df[metadata_cols].values\n",
    "    \n",
    "    return img_paths, metadata, labels\n",
    "\n",
    "X_train_img, X_train_meta, y_train = extract_features(train_df)\n",
    "X_val_img, X_val_meta, y_val       = extract_features(val_df)\n",
    "X_test_img, X_test_meta, y_test    = extract_features(test_df)\n",
    "\n",
    "num_classes = len(label_mapping)\n",
    "print(f\"\\nNumber of classes: {num_classes}\")\n",
    "\n",
    "# =========================================================\n",
    "# PYTORCH DATASET CLASS\n",
    "# =========================================================\n",
    "class Derm7ptDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for Derm7pt with images + metadata\n",
    "    \"\"\"\n",
    "    def __init__(self, img_paths, metadata, labels, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.metadata = metadata\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.img_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            # Fallback to black image if loading fails\n",
    "            print(f\"Warning: Failed to load {img_path}, using placeholder\")\n",
    "            image = Image.new(\"RGB\", (224, 224), color=\"black\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get metadata and label\n",
    "        metadata = self.metadata[idx].astype(np.float32)\n",
    "        label = int(self.labels[idx])\n",
    "        \n",
    "        return image, metadata, label\n",
    "\n",
    "# =========================================================\n",
    "# DATA TRANSFORMS\n",
    "# =========================================================\n",
    "# Training transforms (with augmentation) - REDUCED for small dataset\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),  # Reduced from 30\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),  # Reduced\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# =========================================================\n",
    "# CREATE DATASETS\n",
    "# =========================================================\n",
    "train_dataset = Derm7ptDataset(X_train_img, X_train_meta, y_train, transform=train_transform)\n",
    "val_dataset   = Derm7ptDataset(X_val_img, X_val_meta, y_val, transform=val_test_transform)\n",
    "test_dataset  = Derm7ptDataset(X_test_img, X_test_meta, y_test, transform=val_test_transform)\n",
    "\n",
    "print(f\"\\n‚úÖ Created PyTorch Datasets\")\n",
    "print(f\"   - Train: {len(train_dataset)} samples\")\n",
    "print(f\"   - Val:   {len(val_dataset)} samples\")\n",
    "print(f\"   - Test:  {len(test_dataset)} samples\")\n",
    "\n",
    "# =========================================================\n",
    "# CREATE DATALOADERS (EXAMPLE - ADJUST BATCH SIZE AS NEEDED)\n",
    "# =========================================================\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Set to 0 for Windows, increase for Linux/Mac\n",
    "    pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Created DataLoaders (batch_size={BATCH_SIZE})\")\n",
    "print(f\"   - Train batches: {len(train_loader)}\")\n",
    "print(f\"   - Val batches:   {len(val_loader)}\")\n",
    "print(f\"   - Test batches:  {len(test_loader)}\")\n",
    "\n",
    "# =========================================================\n",
    "# EXAMPLE: TEST LOADING A BATCH\n",
    "# =========================================================\n",
    "print(\"\\nüîç Testing batch loading...\")\n",
    "for images, metadata, labels in train_loader:\n",
    "    print(f\"   - Image batch shape:    {images.shape}\")\n",
    "    print(f\"   - Metadata batch shape: {metadata.shape}\")\n",
    "    print(f\"   - Labels batch shape:   {labels.shape}\")\n",
    "    break\n",
    "\n",
    "print(\"\\n‚úÖ Derm7pt data loading complete! Ready for training.\")\n",
    "print(\"\\nüí° Usage in your model:\")\n",
    "print(\"   for images, metadata, labels in train_loader:\")\n",
    "print(\"       # images: torch.Tensor of shape (batch_size, 3, 224, 224)\")\n",
    "print(\"       # metadata: torch.Tensor of shape (batch_size, num_metadata_features)\")\n",
    "print(\"       # labels: torch.Tensor of shape (batch_size,)\")\n",
    "print(\"       # Your training code here...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0081507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =========================================================\n",
    "# # BALANCED BATCH SAMPLER (Paper Implementation)\n",
    "# # =========================================================\n",
    "# # \"Each mini-batch contains an equal number of samples for each label\"\n",
    "# from torch.utils.data import Sampler\n",
    "# import random\n",
    "\n",
    "# class BalancedBatchSampler(Sampler):\n",
    "#     \"\"\"\n",
    "#     Samples k examples per class in each batch to ensure balanced mini-batches.\n",
    "    \n",
    "#     Args:\n",
    "#         labels: Array of labels for the dataset\n",
    "#         k_per_class: Number of samples per class in each batch (e.g., 8)\n",
    "#         num_classes: Total number of classes\n",
    "#         drop_last: Whether to drop the last incomplete batch\n",
    "#     \"\"\"\n",
    "#     def __init__(self, labels, k_per_class=8, num_classes=None, drop_last=True):\n",
    "#         self.labels = np.array(labels)\n",
    "#         self.k_per_class = k_per_class\n",
    "#         self.drop_last = drop_last\n",
    "        \n",
    "#         # Automatically determine number of classes if not provided\n",
    "#         if num_classes is None:\n",
    "#             self.num_classes = len(np.unique(labels))\n",
    "#         else:\n",
    "#             self.num_classes = num_classes\n",
    "        \n",
    "#         # Organize indices by class\n",
    "#         self.class_indices = {}\n",
    "#         for class_idx in range(self.num_classes):\n",
    "#             self.class_indices[class_idx] = np.where(self.labels == class_idx)[0].tolist()\n",
    "        \n",
    "#         # Verify all classes have enough samples\n",
    "#         for class_idx, indices in self.class_indices.items():\n",
    "#             if len(indices) < self.k_per_class:\n",
    "#                 print(f\"Warning: Class {class_idx} has only {len(indices)} samples, less than k={k_per_class}\")\n",
    "    \n",
    "#     def __iter__(self):\n",
    "#         # Shuffle indices within each class\n",
    "#         shuffled_indices = {}\n",
    "#         for class_idx, indices in self.class_indices.items():\n",
    "#             shuffled = indices.copy()\n",
    "#             random.shuffle(shuffled)\n",
    "#             shuffled_indices[class_idx] = shuffled\n",
    "        \n",
    "#         # Create balanced batches\n",
    "#         batch = []\n",
    "#         class_positions = {class_idx: 0 for class_idx in range(self.num_classes)}\n",
    "        \n",
    "#         while True:\n",
    "#             # Check if we can form a complete batch\n",
    "#             can_form_batch = all(\n",
    "#                 class_positions[class_idx] + self.k_per_class <= len(shuffled_indices[class_idx])\n",
    "#                 for class_idx in range(self.num_classes)\n",
    "#             )\n",
    "            \n",
    "#             if not can_form_batch:\n",
    "#                 if not self.drop_last and len(batch) > 0:\n",
    "#                     yield batch\n",
    "#                 break\n",
    "            \n",
    "#             # Sample k examples from each class\n",
    "#             for class_idx in range(self.num_classes):\n",
    "#                 start_pos = class_positions[class_idx]\n",
    "#                 end_pos = start_pos + self.k_per_class\n",
    "#                 batch.extend(shuffled_indices[class_idx][start_pos:end_pos])\n",
    "#                 class_positions[class_idx] = end_pos\n",
    "            \n",
    "#             # Shuffle batch to mix classes\n",
    "#             random.shuffle(batch)\n",
    "#             yield batch\n",
    "#             batch = []\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         # Calculate number of complete batches possible\n",
    "#         min_batches = min(len(indices) // self.k_per_class \n",
    "#                          for indices in self.class_indices.values())\n",
    "#         return min_batches\n",
    "\n",
    "\n",
    "# # =========================================================\n",
    "# # OPTION: USE BALANCED BATCH SAMPLER\n",
    "# # =========================================================\n",
    "# # Set this to True to use balanced batch sampling (paper approach)\n",
    "# USE_BALANCED_SAMPLING = True\n",
    "\n",
    "# if USE_BALANCED_SAMPLING:\n",
    "#     print(\"\\n‚öñÔ∏è Using Balanced Batch Sampling (k samples per class)\")\n",
    "    \n",
    "#     # Determine k per class based on smallest class and desired batch size\n",
    "#     # For Derm7pt with 5 classes: batch_size = num_classes * k_per_class\n",
    "#     # Example: 5 classes * 8 samples/class = 40 total batch size\n",
    "#     k_per_class = 8  # Adjust this value\n",
    "#     effective_batch_size = num_classes * k_per_class\n",
    "    \n",
    "#     print(f\"   - k per class: {k_per_class}\")\n",
    "#     print(f\"   - Effective batch size: {effective_batch_size}\")\n",
    "    \n",
    "#     # Create balanced sampler for training\n",
    "#     train_sampler = BalancedBatchSampler(\n",
    "#         labels=y_train,\n",
    "#         k_per_class=k_per_class,\n",
    "#         num_classes=num_classes,\n",
    "#         drop_last=True\n",
    "#     )\n",
    "    \n",
    "#     # Recreate train loader with balanced sampler\n",
    "#     train_loader = DataLoader(\n",
    "#         train_dataset,\n",
    "#         batch_sampler=train_sampler,  # Use batch_sampler instead of batch_size\n",
    "#         num_workers=0,\n",
    "#         pin_memory=True\n",
    "#     )\n",
    "    \n",
    "#     print(f\"   - Train batches: {len(train_loader)}\")\n",
    "    \n",
    "#     # Val/test loaders remain unchanged\n",
    "#     # (they already exist from previous cell)\n",
    "\n",
    "# else:\n",
    "#     print(\"\\nüì¶ Using standard DataLoader (original approach)\")\n",
    "#     # Standard loaders already created above\n",
    "#     pass\n",
    "\n",
    "# print(\"\\n‚úÖ DataLoader configuration complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f75c2-ea9b-4ab3-b6af-910f0d213eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T06:42:44.626020Z",
     "iopub.status.busy": "2025-04-05T06:42:44.626020Z",
     "iopub.status.idle": "2025-04-05T06:42:44.635404Z",
     "shell.execute_reply": "2025-04-05T06:42:44.635404Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = train_df['label'].nunique()\n",
    "print(\"Number of classes:\", num_classes)\n",
    "non_feature_cols = [\"label\", \"ImagePath\"]\n",
    "X_train_meta = train_df.drop(columns=non_feature_cols)\n",
    "input_dim_meta = X_train_meta.shape[1]\n",
    "print(f\"Metadata input dimension: {input_dim_meta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360bfa12-b774-4b8a-bae9-c0c698db5f98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T06:42:44.641801Z",
     "iopub.status.busy": "2025-04-05T06:42:44.641801Z",
     "iopub.status.idle": "2025-04-05T06:42:47.257653Z",
     "shell.execute_reply": "2025-04-05T06:42:47.257653Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EarlyFusionModel(nn.Module):\n",
    "    def __init__(self, input_dim_meta, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embed metadata to smaller spatial dimensions first\n",
    "        self.meta_embed = nn.Sequential(\n",
    "            nn.Linear(input_dim_meta, 56 * 56),  # Smaller initial dimension\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(56 * 56),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Load PVT v2 model\n",
    "        self.pvt = timm.create_model(\"pvt_v2_b1\", pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "        # Modify the first convolution layer to accept additional channel (4 instead of 3)\n",
    "        first_conv = self.pvt.patch_embed.proj\n",
    "        self.pvt.patch_embed.proj = nn.Conv2d(4, first_conv.out_channels, \n",
    "                                              kernel_size=first_conv.kernel_size,\n",
    "                                              stride=first_conv.stride,\n",
    "                                              padding=first_conv.padding,\n",
    "                                              bias=first_conv.bias is not None)\n",
    "        \n",
    "        # Initialize new channel weights\n",
    "        with torch.no_grad():\n",
    "            self.pvt.patch_embed.proj.weight.data[:, :3] = first_conv.weight.data\n",
    "            self.pvt.patch_embed.proj.weight.data[:, 3:] = first_conv.weight.data.mean(dim=1, keepdim=True) * 0.1\n",
    "\n",
    "    def forward(self, img, meta):\n",
    "        # Reshape metadata to image-like format\n",
    "        batch_size = img.shape[0]\n",
    "        meta_reshaped = self.meta_embed(meta).view(batch_size, 1, 56, 56)\n",
    "        \n",
    "        # Upsample to match image dimensions\n",
    "        meta_upsampled = F.interpolate(meta_reshaped, \n",
    "                                       size=(224, 224), \n",
    "                                       mode='bilinear', \n",
    "                                       align_corners=False)\n",
    "        \n",
    "        # Early fusion\n",
    "        combined_input = torch.cat([img, meta_upsampled], dim=1)\n",
    "        \n",
    "        # Process through modified PVT\n",
    "        out = self.pvt(combined_input)\n",
    "        return out\n",
    "\n",
    "input_dim_meta = X_train_meta.shape[1]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EarlyFusionModel(input_dim_meta, num_classes).to(device)\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model=model, \n",
    "        input_size=[(16, 3, 224, 224), (16, input_dim_meta)],  # Updated for MobileViT input size\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a8b844-ef1a-44cd-8ad1-9b6d630b935a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T06:42:47.259655Z",
     "iopub.status.busy": "2025-04-05T06:42:47.259655Z",
     "iopub.status.idle": "2025-04-05T06:42:47.262253Z",
     "shell.execute_reply": "2025-04-05T06:42:47.262253Z"
    }
   },
   "outputs": [],
   "source": [
    "print(input_dim_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7279bf2a-d008-4abe-b887-366efe15d700",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T06:42:47.264255Z",
     "iopub.status.busy": "2025-04-05T06:42:47.264255Z",
     "iopub.status.idle": "2025-04-05T06:42:47.571407Z",
     "shell.execute_reply": "2025-04-05T06:42:47.571407Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, metas, labels in loader:\n",
    "            imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
    "            outputs = model(imgs, metas)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_preds\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_loss = None  # Monitor loss for early stopping\n",
    "        self.best_accuracy = -np.inf  # Track best accuracy for checkpoint\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss, val_acc, model):\n",
    "        # Monitor validation LOSS for early stopping (lower is better)\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif val_loss >= self.best_loss - self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience} (val_loss: {val_loss:.4f}, best: {self.best_loss:.4f})')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            if self.verbose:\n",
    "                print(f'‚úÖ Validation loss improved ({self.best_loss:.6f} --> {val_loss:.6f})')\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        \n",
    "        # Save checkpoint based on best ACCURACY (not loss)\n",
    "        if val_acc > self.best_accuracy:\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "\n",
    "    def save_checkpoint(self, val_acc, model):\n",
    "        if self.verbose:\n",
    "            print(f'üíæ Validation accuracy improved ({self.best_accuracy:.6f} --> {val_acc:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.best_accuracy = val_acc\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    for images, meta, labels in pbar:\n",
    "        images, meta, labels = images.to(device), meta.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, meta)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optional: Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss/total:.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return running_loss/len(train_loader), correct/total\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, meta, labels in val_loader:\n",
    "            images, meta, labels = images.to(device), meta.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images, meta)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss/len(val_loader), correct/total\n",
    "\n",
    "def train_model_with_scheduler_and_checkpoint(\n",
    "    model, train_loader, val_loader, optimizer, criterion, device, \n",
    "    epochs=20, patience=5, scheduler_patience=5, checkpoint_dir='checkpoints'):\n",
    "    \n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, 'mobilevitdermp.pt')\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=patience, \n",
    "        verbose=True,\n",
    "        path=checkpoint_path\n",
    "    )\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min',  # Monitor loss (lower is better)\n",
    "        patience=scheduler_patience, \n",
    "        verbose=True,\n",
    "        factor=0.1,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    best_model_epoch = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{epochs}')\n",
    "        \n",
    "        # Training phase\n",
    "        train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        # Update scheduler based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Early stopping check (monitors loss, saves best accuracy)\n",
    "        early_stopping(val_loss, val_acc, model)\n",
    "        if val_acc > early_stopping.best_accuracy:\n",
    "            best_model_epoch = epoch + 1\n",
    "            \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"üõë Early stopping triggered (validation loss not improving)\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    \n",
    "    # Plot training curves\n",
    "    plot_training_curves_with_checkpoint(history, best_model_epoch)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def plot_training_curves_with_checkpoint(history, best_model_epoch):\n",
    "    epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Loss curves\n",
    "    ax1.plot(epochs_range, history['train_loss'], label='Training Loss')\n",
    "    ax1.plot(epochs_range, history['val_loss'], label='Validation Loss')\n",
    "    if best_model_epoch:\n",
    "        ax1.axvline(best_model_epoch, color='r', linestyle='--', label='Best Model')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Accuracy curves\n",
    "    ax2.plot(epochs_range, history['train_acc'], label='Training Accuracy')\n",
    "    ax2.plot(epochs_range, history['val_acc'], label='Validation Accuracy')\n",
    "    if best_model_epoch:\n",
    "        ax2.axvline(best_model_epoch, color='r', linestyle='--', label='Best Model')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Learning rate curve\n",
    "    ax3.plot(epochs_range, history['lr'], label='Learning Rate')\n",
    "    if best_model_epoch:\n",
    "        ax3.axvline(best_model_epoch, color='r', linestyle='--', label='Best Model')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Learning Rate')\n",
    "    ax3.set_title('Learning Rate Schedule')\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ef575-4ad7-478b-afc2-51750bd750ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T06:42:47.573408Z",
     "iopub.status.busy": "2025-04-05T06:42:47.573408Z",
     "iopub.status.idle": "2025-04-05T07:50:07.897839Z",
     "shell.execute_reply": "2025-04-05T07:50:07.897839Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Function to evaluate test metrics\n",
    "def evaluate_test_metrics(model, test_loader, device):\n",
    "    true_labels, pred_labels = test(model, test_loader, device)\n",
    "    acc = accuracy_score(true_labels, pred_labels)\n",
    "    precision = precision_score(true_labels, pred_labels, average='macro')\n",
    "    recall = recall_score(true_labels, pred_labels, average='macro')\n",
    "    f1 = f1_score(true_labels, pred_labels, average='macro')\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "# Placeholder for results\n",
    "results = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1_score\": []\n",
    "}\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_model_state = None\n",
    "model = None\n",
    "\n",
    "# Run experiment for 3 random seeds\n",
    "seeds = [42, 123, 569]  # Example random seeds\n",
    "for seed in seeds:\n",
    "    print(f\"\\nTraining with random seed: {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    \n",
    "    # Reinitialize model, optimizer, and criterion\n",
    "    model = EarlyFusionModel(input_dim_meta, num_classes).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Train the model\n",
    "    model, history = train_model_with_scheduler_and_checkpoint(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=100,\n",
    "        patience=5,\n",
    "        scheduler_patience=3,\n",
    "        checkpoint_dir='D:\\\\PAD-UFES\\\\checkpoints'\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    acc, precision, recall, f1 = evaluate_test_metrics(model, test_loader, device)\n",
    "    print(f\"Seed {seed}: Accuracy={acc:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1 Score={f1:.4f}\")\n",
    "    \n",
    "    # Save metrics\n",
    "    results[\"accuracy\"].append(acc)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"recall\"].append(recall)\n",
    "    results[\"f1_score\"].append(f1)\n",
    "    \n",
    "    # Update the best model\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "# Compute average and standard deviation\n",
    "metrics_summary = {}\n",
    "for metric, values in results.items():\n",
    "    avg = np.mean(values)\n",
    "    std_dev = np.std(values)\n",
    "    metrics_summary[metric] = (avg, std_dev)\n",
    "    print(f\"{metric.capitalize()}: Mean={avg:.4f}, StdDev={std_dev:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "print(f\"Best model achieved an accuracy of {best_accuracy:.4f}\")\n",
    "torch.save(best_model_state, 'D:\\\\Dermp7\\\\best_early_fusion_pvtv2smoteDA.pth')\n",
    "print(\"Saved\")\n",
    "model = EarlyFusionModel(input_dim_meta, num_classes).to(device)\n",
    "model.load_state_dict(torch.load('D:\\\\Dermp7\\\\best_early_fusion_pvtv2smoteDA.pth'))\n",
    "model.eval()\n",
    "print(\"Best model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e445513-187f-4d9a-a981-8a88908ab80c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T07:50:07.899839Z",
     "iopub.status.busy": "2025-04-05T07:50:07.899839Z",
     "iopub.status.idle": "2025-04-05T07:50:13.339551Z",
     "shell.execute_reply": "2025-04-05T07:50:13.339551Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def test(model, loader, device, desc=\"Testing\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, metas, labels in tqdm(loader, total=len(loader), desc=desc, unit=\"batch\"):\n",
    "            imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
    "            outputs = model(imgs, metas)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "            running_total += labels.size(0)\n",
    "            tqdm.write(f\"Batch acc: {running_correct / running_total:.4f}\")\n",
    "\n",
    "    return all_labels, all_preds\n",
    "\n",
    "# Run test with progress bar\n",
    "true_labels, pred_labels = test(model, test_loader, device, desc=\"Evaluating on Test\")\n",
    "\n",
    "# Reports\n",
    "unique_labels = sorted(train_df[\"label\"].unique())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names = [k for k, v in sorted(label_mapping.items(), key=lambda x: x[1])]\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, pred_labels, normalize=\"true\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"gray\", fmt=\".2f\",\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted Label\", fontweight=\"bold\")\n",
    "plt.ylabel(\"True Label\", fontweight=\"bold\")\n",
    "plt.title(\"Normalized Confusion Matrix\", fontweight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c59dcc-4a74-43c5-804e-9cb0835d533b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T07:50:13.563469Z",
     "iopub.status.busy": "2025-04-05T07:50:13.563469Z",
     "iopub.status.idle": "2025-04-05T07:50:13.678985Z",
     "shell.execute_reply": "2025-04-05T07:50:13.678985Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- 8 Color-Blind-Safe Colors ---\n",
    "colors = [\n",
    "    \"#0072B2\",  # Blue\n",
    "    \"#E69F00\",  # Orange\n",
    "    \"#56B4E9\",  # Sky Blue\n",
    "    \"#009E73\",  # Bluish Green\n",
    "    \"#F0E442\",  # Yellow\n",
    "    \"#D55E00\",  # Vermillion\n",
    "    \"#CC79A7\",  # Reddish Purple\n",
    "    \"#000000\"   # Black\n",
    "]\n",
    "\n",
    "# --- Number of classes ---\n",
    "n_class = len(class_names)   # should be 8\n",
    "\n",
    "# --- Convert labels to arrays ---\n",
    "true_labels = np.array(true_labels)\n",
    "pred_labels = np.array(pred_labels)\n",
    "\n",
    "# --- Store curves ---\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_class):\n",
    "    # One-vs-rest encoding\n",
    "    fpr[i], tpr[i], _ = roc_curve((true_labels == i).astype(int),\n",
    "                                  (pred_labels == i).astype(int))\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i in range(n_class):\n",
    "    plt.plot(\n",
    "        fpr[i], tpr[i],\n",
    "        color=colors[i],\n",
    "        lw=2,\n",
    "        label=f\"{class_names[i]} (AUC = {roc_auc[i]:.3f})\"\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\", fontweight=\"bold\", fontsize=12)\n",
    "plt.ylabel(\"True Positive Rate\", fontweight=\"bold\", fontsize=12)\n",
    "plt.title(\"ROC Curve (One-vs-Rest)\", fontweight=\"bold\", fontsize=14)\n",
    "\n",
    "plt.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
