{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1cf7d-e12a-469e-b3c6-c37dee98db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.deterministic = True  \n",
    "torch.backends.cudnn.benchmark = False \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "IMAGE_DIR = 'D:\\\\PAD-UFES\\\\images'  \n",
    "METADATA_PATH = 'D:\\\\PAD-UFES\\\\metadata.csv'\n",
    "\n",
    "metadata = pd.read_csv(METADATA_PATH)\n",
    "\n",
    "def preprocess_metadata(metadata):\n",
    "    metadata = metadata.fillna('UNK')\n",
    "\n",
    "    boolean_cols = [\n",
    "        'smoke',\n",
    "        'drink',\n",
    "        'pesticide',\n",
    "        'skin_cancer_history',\n",
    "        'cancer_history',\n",
    "        'has_piped_water',\n",
    "        'has_sewage_system',\n",
    "        'itch',\n",
    "        'grew',\n",
    "        'hurt',\n",
    "        'changed',\n",
    "        'bleed',\n",
    "        'elevation',\n",
    "        'biopsed',\n",
    "    ]\n",
    "    # Ensure columns are strings and lowercase\n",
    "    for col in boolean_cols:\n",
    "        metadata[col] = metadata[col].astype(str).str.lower()\n",
    "    \n",
    "    # Map boolean columns to 1/0/-1\n",
    "    boolean_mapping = {'true': 1, 'false': 0, 'unk': -1}\n",
    "    for col in boolean_cols:\n",
    "        metadata[col] = metadata[col].map(boolean_mapping)\n",
    "    \n",
    "    # Handle categorical variables\n",
    "    categorical_cols = [\n",
    "        'background_father',\n",
    "        'background_mother',\n",
    "        'gender',\n",
    "        'region',\n",
    "        'diagnostic',\n",
    "    ]\n",
    "    # Convert categorical columns to string\n",
    "    for col in categorical_cols:\n",
    "        metadata[col] = metadata[col].astype(str)\n",
    "    \n",
    "    # One-hot encode categorical variables\n",
    "    metadata_encoded = pd.get_dummies(metadata[categorical_cols])\n",
    "    \n",
    "    # Normalize numerical variables\n",
    "    numerical_cols = ['age', 'fitspatrick', 'diameter_1', 'diameter_2']\n",
    "    # Ensure numerical columns are numeric\n",
    "    for col in numerical_cols:\n",
    "        metadata[col] = pd.to_numeric(metadata[col], errors='coerce')\n",
    "    # Fill NaNs in numerical columns with the mean\n",
    "    metadata[numerical_cols] = metadata[numerical_cols].fillna(metadata[numerical_cols].mean())\n",
    "    # Scale numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    metadata_numeric = metadata[numerical_cols]\n",
    "    metadata_numeric_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(metadata_numeric), columns=numerical_cols\n",
    "    )\n",
    "    \n",
    "    # Combine all metadata features\n",
    "    metadata_processed = pd.concat(\n",
    "        [metadata_numeric_scaled.reset_index(drop=True),\n",
    "         metadata_encoded.reset_index(drop=True),\n",
    "         metadata[boolean_cols].reset_index(drop=True)], axis=1\n",
    "    )\n",
    "    \n",
    "    return metadata_processed\n",
    "\n",
    "# Preprocess metadata\n",
    "metadata_processed = preprocess_metadata(metadata)\n",
    "\n",
    "def get_image_paths(metadata, image_dir):\n",
    "    image_paths = []\n",
    "    for idx, row in metadata.iterrows():\n",
    "        filename = row['img_id']\n",
    "        # Ensure filename is a string\n",
    "        filename = str(filename)\n",
    "        # Check if filename has an extension\n",
    "        if not filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Try common extensions\n",
    "            possible_extensions = ['.jpg', '.jpeg', '.png']\n",
    "            found = False\n",
    "            for ext in possible_extensions:\n",
    "                filepath = os.path.join(image_dir, filename + ext)\n",
    "                if os.path.isfile(filepath):\n",
    "                    image_paths.append(filepath)\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                print(f\"Image file not found for ID: {filename}\")\n",
    "                image_paths.append(None)\n",
    "        else:\n",
    "            filepath = os.path.join(image_dir, filename)\n",
    "            if os.path.isfile(filepath):\n",
    "                image_paths.append(filepath)\n",
    "            else:\n",
    "                print(f\"Image file not found: {filepath}\")\n",
    "                image_paths.append(None)\n",
    "    metadata['ImagePath'] = image_paths\n",
    "    return metadata\n",
    "\n",
    "metadata = get_image_paths(metadata, IMAGE_DIR)\n",
    "\n",
    "# Remove entries with missing images\n",
    "metadata = metadata[metadata['ImagePath'].notnull()]\n",
    "metadata_processed = metadata_processed.loc[metadata.index].reset_index(drop=True)\n",
    "metadata = metadata.reset_index(drop=True)\n",
    "\n",
    "# Drop diagnostic-related columns from features\n",
    "diagnostic_cols = ['diagnostic_ACK', 'diagnostic_BCC', 'diagnostic_MEL', 'diagnostic_NEV', 'diagnostic_SCC', 'diagnostic_SEK']\n",
    "metadata_processed = metadata_processed.drop(columns=diagnostic_cols)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(metadata['diagnostic'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Split data into features and labels\n",
    "X_meta = metadata_processed.reset_index(drop=True)\n",
    "X_img_paths = metadata['ImagePath'].reset_index(drop=True)\n",
    "y = pd.Series(y_encoded)\n",
    "\n",
    "X_train_meta, X_temp_meta, X_train_img_paths, X_temp_img_paths, y_train, y_temp = train_test_split(\n",
    "    X_meta,\n",
    "    X_img_paths,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_val_meta, X_test_meta, X_val_img_paths, X_test_img_paths, y_val, y_test = train_test_split(\n",
    "    X_temp_meta,\n",
    "    X_temp_img_paths,\n",
    "    y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "# Load augmented metadata + image paths\n",
    "aug_meta_df   = pd.read_csv(\"D:/PAD-UFES/augmented_metadata.csv\")\n",
    "aug_labels_df = pd.read_csv(\"D:/PAD-UFES/augmented_labels.csv\")\n",
    "\n",
    "# Combine augmented samples with training set\n",
    "X_train_meta_final = pd.concat([X_train_meta, aug_meta_df], ignore_index=True)\n",
    "X_train_img_paths_final = pd.concat([X_train_img_paths.reset_index(drop=True),\n",
    "                                     aug_labels_df['ImagePath']], ignore_index=True)\n",
    "y_train_final = pd.concat([y_train.reset_index(drop=True),\n",
    "                           aug_labels_df['Label']], ignore_index=True)\n",
    "\n",
    "class PADUFESDataset(Dataset):\n",
    "    def __init__(self, img_paths, meta_data, labels, transform=None):\n",
    "        self.img_paths = img_paths.reset_index(drop=True)\n",
    "        self.meta_data = meta_data.reset_index(drop=True)\n",
    "        self.labels = pd.Series(labels).reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        meta = torch.tensor(self.meta_data.iloc[idx].values.astype(np.float32))\n",
    "        label = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        return image, meta, label\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "    transforms.RandomRotation(70),          \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PADUFESDataset(X_train_img_paths_final, X_train_meta_final, y_train_final, transform=train_transform)\n",
    "val_dataset = PADUFESDataset(X_val_img_paths, X_val_meta, y_val, transform=val_test_transform)\n",
    "test_dataset = PADUFESDataset(X_test_img_paths, X_test_meta, y_test, transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"\\n✅ Loaded Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03bc1d7-2dc6-4593-88ad-b9fef91ba1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, metas, labels in loader:\n",
    "            imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
    "            num_nodes = metas.shape[0]\n",
    "            batch_indices = torch.arange(num_nodes).to(device).long()\n",
    "            edge_index = torch.stack([torch.arange(num_nodes), torch.arange(num_nodes)], dim=0).to(device).long()\n",
    "            \n",
    "            outputs = model(imgs, metas, batch_indices)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_preds\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_accuracy_max = -np.inf\n",
    "        \n",
    "    def __call__(self, val_acc, model):\n",
    "        score = val_acc\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "        elif score <= self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_acc, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation accuracy increased ({self.val_accuracy_max:.6f} --> {val_acc:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_accuracy_max = val_acc\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    for images, meta, labels in pbar:\n",
    "        images, meta, labels = images.to(device), meta.to(device), labels.to(device)\n",
    "\n",
    "        num_nodes = meta.shape[0]\n",
    "        batch_indices = torch.arange(num_nodes).to(device).long()\n",
    "        edge_index = torch.stack([torch.arange(num_nodes), torch.arange(num_nodes)], dim=0).to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, meta, batch_indices)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optional: Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss/total:.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return running_loss/len(train_loader), correct/total\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, meta, labels in val_loader:\n",
    "            images, meta, labels = images.to(device), meta.to(device), labels.to(device)\n",
    "\n",
    "            num_nodes = meta.shape[0]\n",
    "            batch_indices = torch.arange(num_nodes).to(device).long()\n",
    "            edge_index = torch.stack([torch.arange(num_nodes), torch.arange(num_nodes)], dim=0).to(device).long()\n",
    "            \n",
    "            outputs = model(images, meta, batch_indices)\n",
    "            loss = criterion(outputs, labels)\n",
    "                \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss/len(val_loader), correct/total\n",
    "\n",
    "def train_model_with_scheduler_and_checkpoint(\n",
    "    model, train_loader, val_loader, optimizer, criterion, device, \n",
    "    epochs=20, patience=5, scheduler_patience=5, checkpoint_dir='checkpoints'):\n",
    "    \n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, 'coatnet.pt')\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=patience, \n",
    "        verbose=True, \n",
    "        path=checkpoint_path\n",
    "    )\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='max',  # Changed to max since we're monitoring accuracy\n",
    "        patience=scheduler_patience, \n",
    "        verbose=True,\n",
    "        factor=0.1,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    best_model_epoch = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{epochs}')\n",
    "        \n",
    "        # Training phase\n",
    "        train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        # Update scheduler based on validation accuracy\n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # Early stopping check\n",
    "        early_stopping(val_acc, model)\n",
    "        if val_acc > early_stopping.val_accuracy_max:\n",
    "            best_model_epoch = epoch + 1\n",
    "            \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    \n",
    "    # Plot training curves\n",
    "    plot_training_curves_with_checkpoint(history, best_model_epoch)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def plot_training_curves_with_checkpoint(history, best_model_epoch):\n",
    "    epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Loss curves\n",
    "    ax1.plot(epochs_range, history['train_loss'], label='Training Loss')\n",
    "    ax1.plot(epochs_range, history['val_loss'], label='Validation Loss')\n",
    "    if best_model_epoch:\n",
    "        ax1.axvline(best_model_epoch, color='r', linestyle='--', label='Best Model')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Accuracy curves\n",
    "    ax2.plot(epochs_range, history['train_acc'], label='Training Accuracy')\n",
    "    ax2.plot(epochs_range, history['val_acc'], label='Validation Accuracy')\n",
    "    if best_model_epoch:\n",
    "        ax2.axvline(best_model_epoch, color='r', linestyle='--', label='Best Model')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Learning rate curve\n",
    "    ax3.plot(epochs_range, history['lr'], label='Learning Rate')\n",
    "    if best_model_epoch:\n",
    "        ax3.axvline(best_model_epoch, color='r', linestyle='--', label='Best Model')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Learning Rate')\n",
    "    ax3.set_title('Learning Rate Schedule')\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6cbfe8-8259-487c-9387-335253fd92c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_cluster import knn_graph\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# IMPROVED MODEL (A FIXED TO MATCH B'S BEHAVIOR)\n",
    "# =========================================================\n",
    "class EarlyFusionWithDynamicGCN(nn.Module):\n",
    "    def __init__(self, input_dim_meta, num_classes, k=8):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "\n",
    "        # --- GCN Layers ---\n",
    "        self.gcn1 = GCNConv(input_dim_meta, 64)\n",
    "        self.gcn2 = GCNConv(64, 32)\n",
    "        self.res_proj = nn.Linear(64, 32)\n",
    "\n",
    "        # --- metadata → pseudo image ---\n",
    "        self.meta_to_image = nn.Sequential(\n",
    "            nn.Linear(32, 56 * 56),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(56 * 56),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # --- MobileViT backbone ---\n",
    "        self.mobilevit = timm.create_model(\n",
    "            \"mobilevit_s.cvnets_in1k\",\n",
    "            pretrained=True,\n",
    "            num_classes=0\n",
    "        )\n",
    "\n",
    "        # --- Modify first conv to accept 4 channels ---\n",
    "        stem_conv = self.mobilevit.stem.conv\n",
    "        new_conv = nn.Conv2d(\n",
    "            4, stem_conv.out_channels,\n",
    "            kernel_size=stem_conv.kernel_size,\n",
    "            stride=stem_conv.stride,\n",
    "            padding=stem_conv.padding,\n",
    "            bias=stem_conv.bias is not None\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # copy RGB weights\n",
    "            new_conv.weight[:, :3] = stem_conv.weight\n",
    "            # tiny weight for metadata channel\n",
    "            new_conv.weight[:, 3:] = stem_conv.weight.mean(dim=1, keepdim=True) * 0.1\n",
    "            # copy bias if exists\n",
    "            if stem_conv.bias is not None:\n",
    "                new_conv.bias = stem_conv.bias.clone()\n",
    "\n",
    "        self.mobilevit.stem.conv = new_conv\n",
    "\n",
    "        # keep only first 4 stages\n",
    "        self.mobilevit.stages = nn.Sequential(\n",
    "            *list(self.mobilevit.stages.children())[:4]\n",
    "        )\n",
    "        self.mobilevit.final_conv = nn.Identity()\n",
    "        self.mobilevit.head = nn.Identity()\n",
    "\n",
    "        # --- Post Conv ---\n",
    "        self.post_conv = nn.Sequential(\n",
    "            nn.Conv2d(128, 160, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # --- Classifier ---\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, meta, batch_idx):\n",
    "        B = meta.size(0)\n",
    "\n",
    "        # CORRECT: dynamic kNN graph WITHOUT self-loops\n",
    "        edge_index = knn_graph(meta, k=self.k, batch=batch_idx)\n",
    "\n",
    "        # GCN + residual\n",
    "        x1 = F.relu(self.gcn1(meta, edge_index))\n",
    "        x2 = F.relu(self.gcn2(x1, edge_index) + self.res_proj(x1))\n",
    "\n",
    "        # Metadata → pseudo-image\n",
    "        meta_img = self.meta_to_image(x2).view(B, 1, 56, 56)\n",
    "        meta_img = F.interpolate(meta_img, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        # Early fusion (4 channels)\n",
    "        x = torch.cat([img, meta_img], dim=1)\n",
    "\n",
    "        # CNN forward\n",
    "        feats = self.mobilevit.stem(x)\n",
    "        feats = self.mobilevit.stages(feats)\n",
    "        feats = self.post_conv(feats)\n",
    "        feats = self.pool(feats).view(B, -1)\n",
    "\n",
    "        return self.classifier(feats)\n",
    "    \n",
    "from torchinfo import summary\n",
    "\n",
    "input_dim_meta = 59\n",
    "num_classes = 6\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EarlyFusionWithDynamicGCN(input_dim_meta, num_classes).to(device)\n",
    "\n",
    "dummy_img = torch.randn(batch_size, 3, 224, 224).to(device)\n",
    "dummy_meta = torch.randn(batch_size, input_dim_meta).to(device)\n",
    "dummy_batch_idx = torch.arange(batch_size).to(device)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=[dummy_img, dummy_meta, dummy_batch_idx],\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    depth=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a8b844-ef1a-44cd-8ad1-9b6d630b935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_dim_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd9eb80-ceed-4ace-b395-d2e315118b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EarlyFusionModel(nn.Module):\n",
    "    def __init__(self, input_dim_meta, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embed metadata to smaller spatial dimensions first\n",
    "        self.meta_embed = nn.Sequential(\n",
    "            nn.Linear(input_dim_meta, 56 * 56),  # Smaller initial dimension\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(56 * 56),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Load PVT v2 model\n",
    "        self.pvt = timm.create_model(\"pvt_v2_b1\", pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "        # Modify the first convolution layer to accept additional channel (4 instead of 3)\n",
    "        first_conv = self.pvt.patch_embed.proj\n",
    "        self.pvt.patch_embed.proj = nn.Conv2d(4, first_conv.out_channels, \n",
    "                                              kernel_size=first_conv.kernel_size,\n",
    "                                              stride=first_conv.stride,\n",
    "                                              padding=first_conv.padding,\n",
    "                                              bias=first_conv.bias is not None)\n",
    "        \n",
    "        # Initialize new channel weights\n",
    "        with torch.no_grad():\n",
    "            self.pvt.patch_embed.proj.weight.data[:, :3] = first_conv.weight.data\n",
    "            self.pvt.patch_embed.proj.weight.data[:, 3:] = first_conv.weight.data.mean(dim=1, keepdim=True) * 0.1\n",
    "\n",
    "    def forward(self, img, meta):\n",
    "        # Reshape metadata to image-like format\n",
    "        batch_size = img.shape[0]\n",
    "        meta_reshaped = self.meta_embed(meta).view(batch_size, 1, 56, 56)\n",
    "        \n",
    "        # Upsample to match image dimensions\n",
    "        meta_upsampled = F.interpolate(meta_reshaped, \n",
    "                                       size=(224, 224), \n",
    "                                       mode='bilinear', \n",
    "                                       align_corners=False)\n",
    "        \n",
    "        # Early fusion\n",
    "        combined_input = torch.cat([img, meta_upsampled], dim=1)\n",
    "        \n",
    "        # Process through modified PVT\n",
    "        out = self.pvt(combined_input)\n",
    "        return out\n",
    "\n",
    "input_dim_meta = X_train_meta.shape[1]\n",
    "num_classes = 6\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EarlyFusionModel(input_dim_meta, num_classes).to(device)\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model=model, \n",
    "        input_size=[(16, 3, 224, 224), (16, input_dim_meta)],  \n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")\n",
    "\n",
    "pv2_model = EarlyFusionModel(input_dim_meta=input_dim_meta, num_classes=num_classes).to(device)\n",
    "pv2_model.load_state_dict(torch.load('D:\\\\PAD-UFES\\\\best_early_fusion_pvtv2smoteDA.pth'))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pv2_model.to(device)\n",
    "\n",
    "true_labels, pred_labels = test(pv2_model, test_loader, device)\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(true_labels, pred_labels, digits=4,target_names=class_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "cm = confusion_matrix(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa4a19-7a92-4217-971a-d750b9868c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm  \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EarlyFusionModel(nn.Module):\n",
    "    def __init__(self, input_dim_meta, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embed metadata to smaller spatial dimensions first\n",
    "        self.meta_embed = nn.Sequential(\n",
    "            nn.Linear(input_dim_meta, 64 * 64),  # Updated for mobilevit's smaller receptive field\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64 * 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Load MobileViT model\n",
    "        self.mobilevit = timm.create_model(\"mobilevit_s.cvnets_in1k\", pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "        # Inspect the model to identify the first conv layer\n",
    "        # Modify the first conv layer to accept additional channel\n",
    "        first_conv = self.mobilevit.stem.conv  # `stem.conv` is the correct initial layer\n",
    "        self.mobilevit.stem.conv = nn.Conv2d(4, first_conv.out_channels, \n",
    "                                             kernel_size=first_conv.kernel_size, \n",
    "                                             stride=first_conv.stride, \n",
    "                                             padding=first_conv.padding, \n",
    "                                             bias=first_conv.bias)\n",
    "        \n",
    "        # Initialize new channel weights\n",
    "        with torch.no_grad():\n",
    "            self.mobilevit.stem.conv.weight.data[:, :3] = first_conv.weight.data\n",
    "            # Initialize the new channel with smaller weights to prevent dominating\n",
    "            self.mobilevit.stem.conv.weight.data[:, 3:] = first_conv.weight.data.mean(dim=1, keepdim=True) * 0.1\n",
    "\n",
    "    def forward(self, img, meta):\n",
    "        # Reshape metadata to image-like format\n",
    "        batch_size = img.shape[0]\n",
    "        meta_reshaped = self.meta_embed(meta).view(batch_size, 1, 64, 64)\n",
    "        \n",
    "        # Upsample to match image dimensions\n",
    "        meta_upsampled = F.interpolate(meta_reshaped, \n",
    "                                       size=(224, 224),  # MobileViT expects 256x256\n",
    "                                       mode='bilinear', \n",
    "                                       align_corners=False)\n",
    "        \n",
    "        # Early fusion\n",
    "        combined_input = torch.cat([img, meta_upsampled], dim=1)\n",
    "        \n",
    "        # Process through modified MobileViT\n",
    "        out = self.mobilevit(combined_input)\n",
    "        return out\n",
    "\n",
    "# Assuming X_train_meta and other variables are defined\n",
    "input_dim_meta = X_train_meta.shape[1]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EarlyFusionModel(input_dim_meta, num_classes).to(device)\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model=model, \n",
    "        input_size=[(16, 3, 224, 224), (16, input_dim_meta)],  # Updated for MobileViT input size\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")\n",
    "\n",
    "mobilevit_model = EarlyFusionModel(input_dim_meta=input_dim_meta, num_classes=num_classes).to(device)\n",
    "mobilevit_model.load_state_dict(torch.load('D:\\\\PAD-UFES\\\\best_early_fusion_mobilevitDA.pth'))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mobilevit_model.to(device)\n",
    "\n",
    "true_labels, pred_labels = test(mobilevit_model, test_loader, device)\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(true_labels, pred_labels, digits=4,target_names=class_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "cm = confusion_matrix(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228b6d07-a7b1-493b-a95e-08d3afca5c91",
   "metadata": {},
   "source": [
    "<h1>Simple Averaging</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeee46d-8551-4663-89f4-dad23ae284e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to set random seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # If using CUDA\n",
    "\n",
    "def test_ensemble(models, loader, device):\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, metas, labels in loader:\n",
    "            imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
    "            \n",
    "            # Initialize a list to store individual model predictions\n",
    "            model_outputs = []\n",
    "            \n",
    "            # Get predictions from each model and store\n",
    "            for model in models:\n",
    "                outputs = model(imgs, metas)\n",
    "                model_outputs.append(outputs)\n",
    "            \n",
    "            # Stack model outputs along a new axis (axis 0: models)\n",
    "            model_outputs = torch.stack(model_outputs, dim=0)\n",
    "            \n",
    "            # Average the outputs along the new axis (across models)\n",
    "            avg_outputs = model_outputs.mean(dim=0)  # Averaging logits/probabilities\n",
    "\n",
    "            # Convert the averaged outputs to predicted labels\n",
    "            _, predicted = torch.max(avg_outputs, 1)\n",
    "\n",
    "            # Store the predictions and the true labels\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_preds\n",
    "\n",
    "\n",
    "# Function to calculate metrics and return mean ± std deviation\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='macro')\n",
    "    recall = recall_score(true_labels, predictions, average='macro')\n",
    "    f1 = f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "# Main loop to test the ensemble and calculate metrics with standard deviation\n",
    "def evaluate_ensemble(models, test_loader, device, seeds):\n",
    "    accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
    "\n",
    "    # Loop through predefined seeds\n",
    "    for seed in seeds:\n",
    "        set_seed(seed)  # Set the random seed for reproducibility\n",
    "        \n",
    "        # Run the ensemble evaluation\n",
    "        true_labels, ensemble_preds = test_ensemble(models, test_loader, device)\n",
    "\n",
    "        # Calculate metrics for this run\n",
    "        accuracy, precision, recall, f1 = calculate_metrics(true_labels, ensemble_preds)\n",
    "\n",
    "        # Store metrics\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Calculate mean and standard deviation for each metric\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "\n",
    "    mean_precision = np.mean(precisions)\n",
    "    std_precision = np.std(precisions)\n",
    "\n",
    "    mean_recall = np.mean(recalls)\n",
    "    std_recall = np.std(recalls)\n",
    "\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    std_f1 = np.std(f1_scores)\n",
    "\n",
    "    # Print out results\n",
    "    print(f\"Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "    print(f\"Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "    print(f\"Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "    print(f\"F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "\n",
    "# # Example usage with 4 models:\n",
    "# models = [mobilevit_model, pv2_model, swin_model]  # List of models\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Fi``xed random seeds to use\n",
    "# seeds = [42, 123, 569]\n",
    "\n",
    "# # Assume test_loader is defined (DataLoader for test set)\n",
    "# evaluate_ensemble(models, test_loader, device, seeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf72c8-6520-40e5-b7a6-620f940f504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self, models, ensemble_method=\"mean\"):\n",
    "        \"\"\"\n",
    "        Teacher Model using Ensemble Learning.\n",
    "\n",
    "        Args:\n",
    "            models (list): List of trained models to use for ensembling.\n",
    "            ensemble_method (str): \"mean\" for averaging logits, \"vote\" for majority voting.\n",
    "        \"\"\"\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.models = models\n",
    "        self.ensemble_method = ensemble_method\n",
    "\n",
    "        # Ensure all models are in eval mode and no gradients are computed\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, img, meta):\n",
    "        \"\"\"\n",
    "        Forward pass through the ensemble teacher model.\n",
    "\n",
    "        Args:\n",
    "            img (torch.Tensor): Batch of images.\n",
    "            meta (torch.Tensor): Batch of metadata.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The ensembled output (soft probabilities).\n",
    "        \"\"\"\n",
    "        model_outputs = []\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation for teacher\n",
    "            for model in self.models:\n",
    "                outputs = model(img, meta)\n",
    "                model_outputs.append(outputs)\n",
    "\n",
    "        # Convert list to tensor shape [num_models, batch_size, num_classes]\n",
    "        model_outputs = torch.stack(model_outputs, dim=0)\n",
    "\n",
    "        if self.ensemble_method == \"mean\":\n",
    "            # Soft-label generation: Averaging logits\n",
    "            avg_outputs = model_outputs.mean(dim=0)  # Shape [batch_size, num_classes]\n",
    "        elif self.ensemble_method == \"vote\":\n",
    "            # Majority voting: Get the most common prediction\n",
    "            _, predictions = torch.max(model_outputs, dim=2)  # Shape [num_models, batch_size]\n",
    "            avg_outputs = predictions.mode(dim=0).values  # Majority vote\n",
    "\n",
    "        return avg_outputs  # These are the soft labels for KD\n",
    "\n",
    "# teacher_model = TeacherModel(models=[mobilevit_model, pv2_model, swin_model, xception_model], ensemble_method=\"mean\")\n",
    "\n",
    "# # Move to the correct device (CPU/GPU)\n",
    "# teacher_model = teacher_model.to(device)\n",
    "\n",
    "# true_labels, pred_labels = test(teacher_model, test_loader, device)\n",
    "\n",
    "# class_names = label_encoder.classes_\n",
    "# report = classification_report(true_labels, pred_labels, digits=4,target_names=class_names)\n",
    "# print(\"Classification Report:\")\n",
    "# print(report)\n",
    "# cm = confusion_matrix(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a76476-b4e0-40e5-8df6-9b9f0fa59da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = TeacherModel(models=[mobilevit_model, pv2_model], ensemble_method=\"mean\")\n",
    "\n",
    "# Move to the correct device (CPU/GPU)\n",
    "teacher_model = teacher_model.to(device)\n",
    "\n",
    "true_labels, pred_labels = test(teacher_model, test_loader, device)\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(true_labels, pred_labels, digits=4,target_names=class_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "cm = confusion_matrix(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056199b-391c-45bf-aade-6eafe13f469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# ---- Teacher Model (Assumed Already Defined and Loaded) ----\n",
    "teacher_model = TeacherModel(models=[mobilevit_model, pv2_model], ensemble_method=\"mean\").to(device)\n",
    "\n",
    "# ---- Utility Functions ----\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def evaluate_student(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, metas, labels in test_loader:\n",
    "            images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "            batch_indices = torch.arange(metas.size(0)).to(device).long()\n",
    "            outputs = model(images, metas, batch_indices)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    \n",
    "    return accuracy, f1, precision, recall\n",
    "\n",
    "def plot_training_curves(history, seed):\n",
    "    epochs_range = range(1, len(history[\"train_loss\"]) + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(epochs_range, history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"Loss Curve (Seed: {seed})\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, history[\"train_acc\"], label=\"Train Acc\")\n",
    "    plt.plot(epochs_range, history[\"val_acc\"], label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"Accuracy Curve (Seed: {seed})\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ---- Training with Knowledge Distillation ----\n",
    "def train_student_model_kd(student_model, teacher_model, train_loader, val_loader, test_loader,\n",
    "                           device, alpha=0.5, temperature=3.0, epochs=100, patience=10):\n",
    "    student_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    kl_div_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=5, verbose=True)\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_val_model_state = None\n",
    "    best_test_loss = float('inf')\n",
    "    best_test_model_state = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student_model.train()\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        for images, metas, labels in pbar:\n",
    "            images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "            batch_indices = torch.arange(metas.size(0)).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            student_outputs = student_model(images, metas, batch_indices)\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(images, metas)\n",
    "\n",
    "            loss_hard = criterion(student_outputs, labels)\n",
    "            loss_soft = kl_div_loss(\n",
    "                F.log_softmax(student_outputs / temperature, dim=1),\n",
    "                F.softmax(teacher_outputs / temperature, dim=1)\n",
    "            )\n",
    "            loss = (1 - alpha) * loss_hard + alpha * (temperature ** 2) * loss_soft\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = student_outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'acc': f\"{100. * correct / total:.2f}%\"})\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_accuracy)\n",
    "\n",
    "        # --- Validation ---\n",
    "        student_model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, metas, labels in val_loader:\n",
    "                images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "                batch_indices = torch.arange(metas.size(0)).to(device)\n",
    "                outputs = student_model(images, metas, batch_indices)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_accuracy = correct / total\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}: Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "        # --- Evaluate on Test Set ---\n",
    "        student_model.eval()\n",
    "        all_labels, all_preds = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, metas, labels in test_loader:\n",
    "                images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "                batch_indices = torch.arange(metas.size(0)).to(device).long()\n",
    "                outputs = student_model(images, metas, batch_indices)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_preds = np.array(all_preds)\n",
    "\n",
    "        test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        test_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        test_precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        test_recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Test Acc: {test_accuracy:.4f}, \"\n",
    "              f\"F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")\n",
    "\n",
    "        # --- Track Best Val Accuracy ---\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_val_model_state = student_model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # --- Track Best Test Loss (optional) ---\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, metas, labels in test_loader:\n",
    "                images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "                batch_indices = torch.arange(metas.size(0)).to(device)\n",
    "                outputs = student_model(images, metas, batch_indices)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        if avg_test_loss < best_test_loss:\n",
    "            best_test_loss = avg_test_loss\n",
    "            best_test_model_state = student_model.state_dict()\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    # --- Save and Return Best Models ---\n",
    "    if best_val_model_state:\n",
    "        torch.save(best_val_model_state, f\"student_model_val_acc_seed{seed}.pth\")\n",
    "    if best_test_model_state:\n",
    "        torch.save(best_test_model_state, f\"student_model_test_loss_seed{seed}.pth\")\n",
    "\n",
    "    return best_val_model_state, history, best_val_accuracy\n",
    "\n",
    "# ---- Main Experiment Loop ----\n",
    "seeds = [42, 123, 569]\n",
    "best_overall_model = None\n",
    "best_overall_accuracy = 0.0\n",
    "\n",
    "results = {\"accuracy\": [], \"f1\": [], \"precision\": [], \"recall\": []}\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\n--- Training with Seed {seed} ---\")\n",
    "    set_seed(seed)\n",
    "    student_model = EarlyFusionWithDynamicGCN(input_dim_meta=59, num_classes=6).to(device)\n",
    "\n",
    "    best_model_state, history, val_acc = train_student_model_kd(\n",
    "        student_model=student_model,\n",
    "        teacher_model=teacher_model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        alpha=0.2,\n",
    "        temperature=9.0,\n",
    "        epochs=100,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    plot_training_curves(history, seed)\n",
    "\n",
    "    # ---- Restore Best Validation Model Before Final Test ----\n",
    "    print(\"\\nRestoring best validation model for final test evaluation...\")\n",
    "    student_model.load_state_dict(best_model_state)\n",
    "\n",
    "    # ---- Final Evaluation on Test Set (Correct Model) ----\n",
    "    acc, f1, prec, recall = evaluate_student(student_model, test_loader, device)\n",
    "    results[\"accuracy\"].append(acc)\n",
    "    results[\"f1\"].append(f1)\n",
    "    results[\"precision\"].append(prec)\n",
    "    results[\"recall\"].append(recall)\n",
    "\n",
    "    if val_acc > best_overall_accuracy:\n",
    "        best_overall_model = student_model\n",
    "        best_overall_accuracy = val_acc\n",
    "\n",
    "# ---- Save Final Best Model ----\n",
    "torch.save(best_overall_model.state_dict(), \"best_student_model_final2.pth\")\n",
    "print(f\"\\nBest Val Accuracy Model saved (Accuracy: {best_overall_accuracy:.4f})\")\n",
    "\n",
    "# ---- Summary ----\n",
    "print(\"\\n--- Final Evaluation across Seeds ---\")\n",
    "for metric in results:\n",
    "    print(f\"{metric.capitalize()}: {np.mean(results[metric]):.4f} ± {np.std(results[metric]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f05ae-d307-49d9-88c4-1772f6bff181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the best model\n",
    "best_model = EarlyFusionWithDynamicGCN(input_dim_meta=59, num_classes=6).to(device)\n",
    "best_model.load_state_dict(torch.load(\"best_student_model_final2.pth\"))\n",
    "best_model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, metas, labels in test_loader:\n",
    "        images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "        batch_indices = torch.arange(metas.size(0)).to(device).long()\n",
    "        outputs = student_model(images, metas, batch_indices)        \n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# Compute classification report\n",
    "class_report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
    "\n",
    "# Compute normalized confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds, normalize=\"true\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(class_report)\n",
    "\n",
    "# Display confusion matrix (black and white)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"gray\", fmt=\".2f\", xticklabels=class_names, yticklabels=class_names, cbar=True)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot ROC-AUC curve for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    fpr, tpr, _ = roc_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")  # Diagonal line for reference\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC-AUC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Optional: Compute and plot Precision-Recall Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    precision, recall, _ = precision_recall_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{class_name}\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e7ae6-4877-4359-8781-0b72c3ea3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Ensure the teacher model is in eval mode\n",
    "teacher_model.eval()\n",
    "\n",
    "# Collect true labels and predictions\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, metas, labels in test_loader:\n",
    "        images, metas, labels = images.to(device), metas.to(device), labels.to(device)\n",
    "\n",
    "        outputs = teacher_model(images, metas)\n",
    "        probs = F.softmax(outputs, dim=1) if outputs.dim() == 2 else outputs\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# Compute classification report\n",
    "class_report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
    "\n",
    "# Compute normalized confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds, normalize=\"true\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(class_report)\n",
    "\n",
    "# Display confusion matrix (Blues colormap)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\".2f\", xticklabels=class_names, yticklabels=class_names, cbar=True)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot ROC-AUC curve for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    fpr, tpr, _ = roc_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")  # Diagonal line for reference\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC-AUC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot Precision-Recall Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    precision, recall, _ = precision_recall_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{class_name}\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
